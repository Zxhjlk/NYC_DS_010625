{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1e2e623",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div style=\"color:white;\n",
    "           display:fill;\n",
    "           border-radius:5px;\n",
    "           background-color:#5642C5;\n",
    "           font-size:200%;\n",
    "           font-family:Arial;letter-spacing:0.5px\">\n",
    "\n",
    "<p width = 20%, style=\"padding: 10px;\n",
    "              color:white;\">\n",
    "Pandas: Groupby Operations and Transformations\n",
    "              \n",
    "</p>\n",
    "</div>\n",
    "\n",
    "Data Science Cohort Live NYC Jan 2025\n",
    "<p>Phase 1</p>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<div align = \"right\">\n",
    "<img src=\"Images/flatiron-school-logo.png\" align = \"right\" width=\"200\"/>\n",
    "</div>\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861b0f9d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Categorical variable taking on a few discrete values.\n",
    "\n",
    "Each of these values form a group. Want to:\n",
    "- Calculate statistics on various quantities for each group (mean, etc.)\n",
    "- Transform/scale certain columns differently for each group.\n",
    "\n",
    "\n",
    "DataFrame.groupby() allows us to do this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1678c1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Take the Titanic dataset again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3309b922",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "titanic_df = pd.read_csv('Data/titanic.csv')\n",
    "titanic_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd05fa5b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Sex as  relevant categorical variable:\n",
    "- survival rate\n",
    "- distribution of ages\n",
    "- fare"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2acd2c02",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### The groupby object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e82a941",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pandas.core.groupby.generic.DataFrameGroupBy object at 0x0000021BA24A3750>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_subset = titanic_df[['Sex', 'Survived', 'Age', 'Fare']]\n",
    "titanic_subset.groupby('Sex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db31580f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on DataFrameGroupBy in module pandas.core.groupby.generic object:\n",
      "\n",
      "class DataFrameGroupBy(pandas.core.groupby.groupby.GroupBy)\n",
      " |  DataFrameGroupBy(obj: 'NDFrameT', keys: '_KeysArgType | None' = None, axis: 'Axis' = 0, level: 'IndexLabel | None' = None, grouper: 'ops.BaseGrouper | None' = None, exclusions: 'frozenset[Hashable] | None' = None, selection: 'IndexLabel | None' = None, as_index: 'bool' = True, sort: 'bool' = True, group_keys: 'bool' = True, observed: 'bool | lib.NoDefault' = <no_default>, dropna: 'bool' = True) -> 'None'\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      DataFrameGroupBy\n",
      " |      pandas.core.groupby.groupby.GroupBy\n",
      " |      pandas.core.groupby.groupby.BaseGroupBy\n",
      " |      pandas.core.base.PandasObject\n",
      " |      pandas.core.accessor.DirNamesMixin\n",
      " |      pandas.core.base.SelectionMixin\n",
      " |      typing.Generic\n",
      " |      pandas.core.groupby.indexing.GroupByIndexingMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __getitem__(self, key) -> 'DataFrameGroupBy | SeriesGroupBy'\n",
      " |  \n",
      " |  agg = aggregate(self, func=None, *args, engine=None, engine_kwargs=None, **kwargs)\n",
      " |  \n",
      " |  aggregate(self, func=None, *args, engine=None, engine_kwargs=None, **kwargs)\n",
      " |      Aggregate using one or more operations over the specified axis.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : function, str, list, dict or None\n",
      " |          Function to use for aggregating the data. If a function, must either\n",
      " |          work when passed a DataFrame or when passed to DataFrame.apply.\n",
      " |      \n",
      " |          Accepted combinations are:\n",
      " |      \n",
      " |          - function\n",
      " |          - string function name\n",
      " |          - list of functions and/or function names, e.g. ``[np.sum, 'mean']``\n",
      " |          - dict of axis labels -> functions, function names or list of such.\n",
      " |          - None, in which case ``**kwargs`` are used with Named Aggregation. Here the\n",
      " |            output has one column for each element in ``**kwargs``. The name of the\n",
      " |            column is keyword, whereas the value determines the aggregation used to compute\n",
      " |            the values in the column.\n",
      " |      \n",
      " |            Can also accept a Numba JIT function with\n",
      " |            ``engine='numba'`` specified. Only passing a single function is supported\n",
      " |            with this engine.\n",
      " |      \n",
      " |            If the ``'numba'`` engine is chosen, the function must be\n",
      " |            a user defined function with ``values`` and ``index`` as the\n",
      " |            first and second arguments respectively in the function signature.\n",
      " |            Each group's index will be passed to the user defined function\n",
      " |            and optionally available for use.\n",
      " |      \n",
      " |      *args\n",
      " |          Positional arguments to pass to func.\n",
      " |      engine : str, default None\n",
      " |          * ``'cython'`` : Runs the function through C-extensions from cython.\n",
      " |          * ``'numba'`` : Runs the function through JIT compiled code from numba.\n",
      " |          * ``None`` : Defaults to ``'cython'`` or globally setting ``compute.use_numba``\n",
      " |      \n",
      " |      engine_kwargs : dict, default None\n",
      " |          * For ``'cython'`` engine, there are no accepted ``engine_kwargs``\n",
      " |          * For ``'numba'`` engine, the engine can accept ``nopython``, ``nogil``\n",
      " |            and ``parallel`` dictionary keys. The values must either be ``True`` or\n",
      " |            ``False``. The default ``engine_kwargs`` for the ``'numba'`` engine is\n",
      " |            ``{'nopython': True, 'nogil': False, 'parallel': False}`` and will be\n",
      " |            applied to the function\n",
      " |      \n",
      " |      **kwargs\n",
      " |          * If ``func`` is None, ``**kwargs`` are used to define the output names and\n",
      " |            aggregations via Named Aggregation. See ``func`` entry.\n",
      " |          * Otherwise, keyword arguments to be passed into func.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.groupby.apply : Apply function func group-wise\n",
      " |          and combine the results together.\n",
      " |      DataFrame.groupby.transform : Transforms the Series on each group\n",
      " |          based on the given function.\n",
      " |      DataFrame.aggregate : Aggregate using one or more\n",
      " |          operations over the specified axis.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      When using ``engine='numba'``, there will be no \"fall back\" behavior internally.\n",
      " |      The group data and group index will be passed as numpy arrays to the JITed\n",
      " |      user defined function, and no alternative execution attempts will be tried.\n",
      " |      \n",
      " |      Functions that mutate the passed object can produce unexpected\n",
      " |      behavior or errors and are not supported. See :ref:`gotchas.udf-mutation`\n",
      " |      for more details.\n",
      " |      \n",
      " |      .. versionchanged:: 1.3.0\n",
      " |      \n",
      " |          The resulting dtype will reflect the return value of the passed ``func``,\n",
      " |          see the examples below.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame(\n",
      " |      ...     {\n",
      " |      ...         \"A\": [1, 1, 2, 2],\n",
      " |      ...         \"B\": [1, 2, 3, 4],\n",
      " |      ...         \"C\": [0.362838, 0.227877, 1.267767, -0.562860],\n",
      " |      ...     }\n",
      " |      ... )\n",
      " |      \n",
      " |      >>> df\n",
      " |         A  B         C\n",
      " |      0  1  1  0.362838\n",
      " |      1  1  2  0.227877\n",
      " |      2  2  3  1.267767\n",
      " |      3  2  4 -0.562860\n",
      " |      \n",
      " |      The aggregation is for each column.\n",
      " |      \n",
      " |      >>> df.groupby('A').agg('min')\n",
      " |         B         C\n",
      " |      A\n",
      " |      1  1  0.227877\n",
      " |      2  3 -0.562860\n",
      " |      \n",
      " |      Multiple aggregations\n",
      " |      \n",
      " |      >>> df.groupby('A').agg(['min', 'max'])\n",
      " |          B             C\n",
      " |        min max       min       max\n",
      " |      A\n",
      " |      1   1   2  0.227877  0.362838\n",
      " |      2   3   4 -0.562860  1.267767\n",
      " |      \n",
      " |      Select a column for aggregation\n",
      " |      \n",
      " |      >>> df.groupby('A').B.agg(['min', 'max'])\n",
      " |         min  max\n",
      " |      A\n",
      " |      1    1    2\n",
      " |      2    3    4\n",
      " |      \n",
      " |      User-defined function for aggregation\n",
      " |      \n",
      " |      >>> df.groupby('A').agg(lambda x: sum(x) + 2)\n",
      " |          B          C\n",
      " |      A\n",
      " |      1       5       2.590715\n",
      " |      2       9       2.704907\n",
      " |      \n",
      " |      Different aggregations per column\n",
      " |      \n",
      " |      >>> df.groupby('A').agg({'B': ['min', 'max'], 'C': 'sum'})\n",
      " |          B             C\n",
      " |        min max       sum\n",
      " |      A\n",
      " |      1   1   2  0.590715\n",
      " |      2   3   4  0.704907\n",
      " |      \n",
      " |      To control the output names with different aggregations per column,\n",
      " |      pandas supports \"named aggregation\"\n",
      " |      \n",
      " |      >>> df.groupby(\"A\").agg(\n",
      " |      ...     b_min=pd.NamedAgg(column=\"B\", aggfunc=\"min\"),\n",
      " |      ...     c_sum=pd.NamedAgg(column=\"C\", aggfunc=\"sum\"))\n",
      " |         b_min     c_sum\n",
      " |      A\n",
      " |      1      1  0.590715\n",
      " |      2      3  0.704907\n",
      " |      \n",
      " |      - The keywords are the *output* column names\n",
      " |      - The values are tuples whose first element is the column to select\n",
      " |        and the second element is the aggregation to apply to that column.\n",
      " |        Pandas provides the ``pandas.NamedAgg`` namedtuple with the fields\n",
      " |        ``['column', 'aggfunc']`` to make it clearer what the arguments are.\n",
      " |        As usual, the aggregation can be a callable or a string alias.\n",
      " |      \n",
      " |      See :ref:`groupby.aggregate.named` for more.\n",
      " |      \n",
      " |      .. versionchanged:: 1.3.0\n",
      " |      \n",
      " |          The resulting dtype will reflect the return value of the aggregating function.\n",
      " |      \n",
      " |      >>> df.groupby(\"A\")[[\"B\"]].agg(lambda x: x.astype(float).min())\n",
      " |            B\n",
      " |      A\n",
      " |      1   1.0\n",
      " |      2   3.0\n",
      " |  \n",
      " |  boxplot = boxplot_frame_groupby(grouped, subplots: 'bool' = True, column=None, fontsize: 'int | None' = None, rot: 'int' = 0, grid: 'bool' = True, ax=None, figsize: 'tuple[float, float] | None' = None, layout=None, sharex: 'bool' = False, sharey: 'bool' = True, backend=None, **kwargs)\n",
      " |      Make box plots from DataFrameGroupBy data.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      grouped : Grouped DataFrame\n",
      " |      subplots : bool\n",
      " |          * ``False`` - no subplots will be used\n",
      " |          * ``True`` - create a subplot for each group.\n",
      " |      \n",
      " |      column : column name or list of names, or vector\n",
      " |          Can be any valid input to groupby.\n",
      " |      fontsize : float or str\n",
      " |      rot : label rotation angle\n",
      " |      grid : Setting this to True will show the grid\n",
      " |      ax : Matplotlib axis object, default None\n",
      " |      figsize : A tuple (width, height) in inches\n",
      " |      layout : tuple (optional)\n",
      " |          The layout of the plot: (rows, columns).\n",
      " |      sharex : bool, default False\n",
      " |          Whether x-axes will be shared among subplots.\n",
      " |      sharey : bool, default True\n",
      " |          Whether y-axes will be shared among subplots.\n",
      " |      backend : str, default None\n",
      " |          Backend to use instead of the backend specified in the option\n",
      " |          ``plotting.backend``. For instance, 'matplotlib'. Alternatively, to\n",
      " |          specify the ``plotting.backend`` for the whole session, set\n",
      " |          ``pd.options.plotting.backend``.\n",
      " |      **kwargs\n",
      " |          All other plotting keyword arguments to be passed to\n",
      " |          matplotlib's boxplot function.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      dict of key/value = group key/DataFrame.boxplot return value\n",
      " |      or DataFrame.boxplot return value in case subplots=figures=False\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      You can create boxplots for grouped data and show them as separate subplots:\n",
      " |      \n",
      " |      .. plot::\n",
      " |          :context: close-figs\n",
      " |      \n",
      " |          >>> import itertools\n",
      " |          >>> tuples = [t for t in itertools.product(range(1000), range(4))]\n",
      " |          >>> index = pd.MultiIndex.from_tuples(tuples, names=['lvl0', 'lvl1'])\n",
      " |          >>> data = np.random.randn(len(index),4)\n",
      " |          >>> df = pd.DataFrame(data, columns=list('ABCD'), index=index)\n",
      " |          >>> grouped = df.groupby(level='lvl1')\n",
      " |          >>> grouped.boxplot(rot=45, fontsize=12, figsize=(8,10))  # doctest: +SKIP\n",
      " |      \n",
      " |      The ``subplots=False`` option shows the boxplots in a single figure.\n",
      " |      \n",
      " |      .. plot::\n",
      " |          :context: close-figs\n",
      " |      \n",
      " |          >>> grouped.boxplot(subplots=False, rot=45, fontsize=12)  # doctest: +SKIP\n",
      " |  \n",
      " |  corr(self, method: 'str | Callable[[np.ndarray, np.ndarray], float]' = 'pearson', min_periods: 'int' = 1, numeric_only: 'bool' = False) -> 'DataFrame'\n",
      " |      Compute pairwise correlation of columns, excluding NA/null values.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      method : {'pearson', 'kendall', 'spearman'} or callable\n",
      " |          Method of correlation:\n",
      " |      \n",
      " |          * pearson : standard correlation coefficient\n",
      " |          * kendall : Kendall Tau correlation coefficient\n",
      " |          * spearman : Spearman rank correlation\n",
      " |          * callable: callable with input two 1d ndarrays\n",
      " |              and returning a float. Note that the returned matrix from corr\n",
      " |              will have 1 along the diagonals and will be symmetric\n",
      " |              regardless of the callable's behavior.\n",
      " |      min_periods : int, optional\n",
      " |          Minimum number of observations required per pair of columns\n",
      " |          to have a valid result. Currently only available for Pearson\n",
      " |          and Spearman correlation.\n",
      " |      numeric_only : bool, default False\n",
      " |          Include only `float`, `int` or `boolean` data.\n",
      " |      \n",
      " |          .. versionadded:: 1.5.0\n",
      " |      \n",
      " |          .. versionchanged:: 2.0.0\n",
      " |              The default value of ``numeric_only`` is now ``False``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Correlation matrix.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.corrwith : Compute pairwise correlation with another\n",
      " |          DataFrame or Series.\n",
      " |      Series.corr : Compute the correlation between two Series.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Pearson, Kendall and Spearman correlation are currently computed using pairwise complete observations.\n",
      " |      \n",
      " |      * `Pearson correlation coefficient <https://en.wikipedia.org/wiki/Pearson_correlation_coefficient>`_\n",
      " |      * `Kendall rank correlation coefficient <https://en.wikipedia.org/wiki/Kendall_rank_correlation_coefficient>`_\n",
      " |      * `Spearman's rank correlation coefficient <https://en.wikipedia.org/wiki/Spearman%27s_rank_correlation_coefficient>`_\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> def histogram_intersection(a, b):\n",
      " |      ...     v = np.minimum(a, b).sum().round(decimals=1)\n",
      " |      ...     return v\n",
      " |      >>> df = pd.DataFrame([(.2, .3), (.0, .6), (.6, .0), (.2, .1)],\n",
      " |      ...                   columns=['dogs', 'cats'])\n",
      " |      >>> df.corr(method=histogram_intersection)\n",
      " |            dogs  cats\n",
      " |      dogs   1.0   0.3\n",
      " |      cats   0.3   1.0\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([(1, 1), (2, np.nan), (np.nan, 3), (4, 4)],\n",
      " |      ...                   columns=['dogs', 'cats'])\n",
      " |      >>> df.corr(min_periods=3)\n",
      " |            dogs  cats\n",
      " |      dogs   1.0   NaN\n",
      " |      cats   NaN   1.0\n",
      " |  \n",
      " |  corrwith(self, other: 'DataFrame | Series', axis: 'Axis | lib.NoDefault' = <no_default>, drop: 'bool' = False, method: 'CorrelationMethod' = 'pearson', numeric_only: 'bool' = False) -> 'DataFrame'\n",
      " |      Compute pairwise correlation.\n",
      " |      \n",
      " |      Pairwise correlation is computed between rows or columns of\n",
      " |      DataFrame with rows or columns of Series or DataFrame. DataFrames\n",
      " |      are first aligned along both axes before computing the\n",
      " |      correlations.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : DataFrame, Series\n",
      " |          Object with which to compute correlations.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The axis to use. 0 or 'index' to compute row-wise, 1 or 'columns' for\n",
      " |          column-wise.\n",
      " |      drop : bool, default False\n",
      " |          Drop missing indices from result.\n",
      " |      method : {'pearson', 'kendall', 'spearman'} or callable\n",
      " |          Method of correlation:\n",
      " |      \n",
      " |          * pearson : standard correlation coefficient\n",
      " |          * kendall : Kendall Tau correlation coefficient\n",
      " |          * spearman : Spearman rank correlation\n",
      " |          * callable: callable with input two 1d ndarrays\n",
      " |              and returning a float.\n",
      " |      \n",
      " |      numeric_only : bool, default False\n",
      " |          Include only `float`, `int` or `boolean` data.\n",
      " |      \n",
      " |          .. versionadded:: 1.5.0\n",
      " |      \n",
      " |          .. versionchanged:: 2.0.0\n",
      " |              The default value of ``numeric_only`` is now ``False``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Pairwise correlations.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.corr : Compute pairwise correlation of columns.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> index = [\"a\", \"b\", \"c\", \"d\", \"e\"]\n",
      " |      >>> columns = [\"one\", \"two\", \"three\", \"four\"]\n",
      " |      >>> df1 = pd.DataFrame(np.arange(20).reshape(5, 4), index=index, columns=columns)\n",
      " |      >>> df2 = pd.DataFrame(np.arange(16).reshape(4, 4), index=index[:4], columns=columns)\n",
      " |      >>> df1.corrwith(df2)\n",
      " |      one      1.0\n",
      " |      two      1.0\n",
      " |      three    1.0\n",
      " |      four     1.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> df2.corrwith(df1, axis=1)\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |  \n",
      " |  cov(self, min_periods: 'int | None' = None, ddof: 'int | None' = 1, numeric_only: 'bool' = False) -> 'DataFrame'\n",
      " |      Compute pairwise covariance of columns, excluding NA/null values.\n",
      " |      \n",
      " |      Compute the pairwise covariance among the series of a DataFrame.\n",
      " |      The returned data frame is the `covariance matrix\n",
      " |      <https://en.wikipedia.org/wiki/Covariance_matrix>`__ of the columns\n",
      " |      of the DataFrame.\n",
      " |      \n",
      " |      Both NA and null values are automatically excluded from the\n",
      " |      calculation. (See the note below about bias from missing values.)\n",
      " |      A threshold can be set for the minimum number of\n",
      " |      observations for each value created. Comparisons with observations\n",
      " |      below this threshold will be returned as ``NaN``.\n",
      " |      \n",
      " |      This method is generally used for the analysis of time series data to\n",
      " |      understand the relationship between different measures\n",
      " |      across time.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      min_periods : int, optional\n",
      " |          Minimum number of observations required per pair of columns\n",
      " |          to have a valid result.\n",
      " |      \n",
      " |      ddof : int, default 1\n",
      " |          Delta degrees of freedom.  The divisor used in calculations\n",
      " |          is ``N - ddof``, where ``N`` represents the number of elements.\n",
      " |          This argument is applicable only when no ``nan`` is in the dataframe.\n",
      " |      \n",
      " |      numeric_only : bool, default False\n",
      " |          Include only `float`, `int` or `boolean` data.\n",
      " |      \n",
      " |          .. versionadded:: 1.5.0\n",
      " |      \n",
      " |          .. versionchanged:: 2.0.0\n",
      " |              The default value of ``numeric_only`` is now ``False``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          The covariance matrix of the series of the DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.cov : Compute covariance with another Series.\n",
      " |      core.window.ewm.ExponentialMovingWindow.cov : Exponential weighted sample\n",
      " |          covariance.\n",
      " |      core.window.expanding.Expanding.cov : Expanding sample covariance.\n",
      " |      core.window.rolling.Rolling.cov : Rolling sample covariance.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Returns the covariance matrix of the DataFrame's time series.\n",
      " |      The covariance is normalized by N-ddof.\n",
      " |      \n",
      " |      For DataFrames that have Series that are missing data (assuming that\n",
      " |      data is `missing at random\n",
      " |      <https://en.wikipedia.org/wiki/Missing_data#Missing_at_random>`__)\n",
      " |      the returned covariance matrix will be an unbiased estimate\n",
      " |      of the variance and covariance between the member Series.\n",
      " |      \n",
      " |      However, for many applications this estimate may not be acceptable\n",
      " |      because the estimate covariance matrix is not guaranteed to be positive\n",
      " |      semi-definite. This could lead to estimate correlations having\n",
      " |      absolute values which are greater than one, and/or a non-invertible\n",
      " |      covariance matrix. See `Estimation of covariance matrices\n",
      " |      <https://en.wikipedia.org/w/index.php?title=Estimation_of_covariance_\n",
      " |      matrices>`__ for more details.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([(1, 2), (0, 3), (2, 0), (1, 1)],\n",
      " |      ...                   columns=['dogs', 'cats'])\n",
      " |      >>> df.cov()\n",
      " |                dogs      cats\n",
      " |      dogs  0.666667 -1.000000\n",
      " |      cats -1.000000  1.666667\n",
      " |      \n",
      " |      >>> np.random.seed(42)\n",
      " |      >>> df = pd.DataFrame(np.random.randn(1000, 5),\n",
      " |      ...                   columns=['a', 'b', 'c', 'd', 'e'])\n",
      " |      >>> df.cov()\n",
      " |                a         b         c         d         e\n",
      " |      a  0.998438 -0.020161  0.059277 -0.008943  0.014144\n",
      " |      b -0.020161  1.059352 -0.008543 -0.024738  0.009826\n",
      " |      c  0.059277 -0.008543  1.010670 -0.001486 -0.000271\n",
      " |      d -0.008943 -0.024738 -0.001486  0.921297 -0.013692\n",
      " |      e  0.014144  0.009826 -0.000271 -0.013692  0.977795\n",
      " |      \n",
      " |      **Minimum number of periods**\n",
      " |      \n",
      " |      This method also supports an optional ``min_periods`` keyword\n",
      " |      that specifies the required minimum number of non-NA observations for\n",
      " |      each column pair in order to have a valid result:\n",
      " |      \n",
      " |      >>> np.random.seed(42)\n",
      " |      >>> df = pd.DataFrame(np.random.randn(20, 3),\n",
      " |      ...                   columns=['a', 'b', 'c'])\n",
      " |      >>> df.loc[df.index[:5], 'a'] = np.nan\n",
      " |      >>> df.loc[df.index[5:10], 'b'] = np.nan\n",
      " |      >>> df.cov(min_periods=12)\n",
      " |                a         b         c\n",
      " |      a  0.316741       NaN -0.150812\n",
      " |      b       NaN  1.248003  0.191417\n",
      " |      c -0.150812  0.191417  0.895202\n",
      " |  \n",
      " |  fillna(self, value: 'Hashable | Mapping | Series | DataFrame | None' = None, method: 'FillnaOptions | None' = None, axis: 'Axis | None | lib.NoDefault' = <no_default>, inplace: 'bool' = False, limit: 'int | None' = None, downcast=<no_default>) -> 'DataFrame | None'\n",
      " |      Fill NA/NaN values using the specified method within groups.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      value : scalar, dict, Series, or DataFrame\n",
      " |          Value to use to fill holes (e.g. 0), alternately a\n",
      " |          dict/Series/DataFrame of values specifying which value to use for\n",
      " |          each index (for a Series) or column (for a DataFrame).  Values not\n",
      " |          in the dict/Series/DataFrame will not be filled. This value cannot\n",
      " |          be a list. Users wanting to use the ``value`` argument and not ``method``\n",
      " |          should prefer :meth:`.DataFrame.fillna` as this\n",
      " |          will produce the same result and be more performant.\n",
      " |      method : {{'bfill', 'ffill', None}}, default None\n",
      " |          Method to use for filling holes. ``'ffill'`` will propagate\n",
      " |          the last valid observation forward within a group.\n",
      " |          ``'bfill'`` will use next valid observation to fill the gap.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}\n",
      " |          Axis along which to fill missing values. When the :class:`DataFrameGroupBy`\n",
      " |          ``axis`` argument is ``0``, using ``axis=1`` here will produce\n",
      " |          the same results as :meth:`.DataFrame.fillna`. When the\n",
      " |          :class:`DataFrameGroupBy` ``axis`` argument is ``1``, using ``axis=0``\n",
      " |          or ``axis=1`` here will produce the same results.\n",
      " |      \n",
      " |          .. deprecated:: 2.1.0\n",
      " |              For axis=1, operate on the underlying object instead. Otherwise\n",
      " |              the axis keyword is not necessary.\n",
      " |      \n",
      " |      inplace : bool, default False\n",
      " |          Broken. Do not set to True.\n",
      " |      limit : int, default None\n",
      " |          If method is specified, this is the maximum number of consecutive\n",
      " |          NaN values to forward/backward fill within a group. In other words,\n",
      " |          if there is a gap with more than this number of consecutive NaNs,\n",
      " |          it will only be partially filled. If method is not specified, this is the\n",
      " |          maximum number of entries along the entire axis where NaNs will be\n",
      " |          filled. Must be greater than 0 if not None.\n",
      " |      downcast : dict, default is None\n",
      " |          A dict of item->dtype of what to downcast if possible,\n",
      " |          or the string 'infer' which will try to downcast to an appropriate\n",
      " |          equal type (e.g. float64 to int64 if possible).\n",
      " |      \n",
      " |          .. deprecated:: 2.1.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Object with missing values filled.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      ffill : Forward fill values within a group.\n",
      " |      bfill : Backward fill values within a group.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame(\n",
      " |      ...     {\n",
      " |      ...         \"key\": [0, 0, 1, 1, 1],\n",
      " |      ...         \"A\": [np.nan, 2, np.nan, 3, np.nan],\n",
      " |      ...         \"B\": [2, 3, np.nan, np.nan, np.nan],\n",
      " |      ...         \"C\": [np.nan, np.nan, 2, np.nan, np.nan],\n",
      " |      ...     }\n",
      " |      ... )\n",
      " |      >>> df\n",
      " |         key    A    B   C\n",
      " |      0    0  NaN  2.0 NaN\n",
      " |      1    0  2.0  3.0 NaN\n",
      " |      2    1  NaN  NaN 2.0\n",
      " |      3    1  3.0  NaN NaN\n",
      " |      4    1  NaN  NaN NaN\n",
      " |      \n",
      " |      Propagate non-null values forward or backward within each group along columns.\n",
      " |      \n",
      " |      >>> df.groupby(\"key\").fillna(method=\"ffill\")\n",
      " |           A    B   C\n",
      " |      0  NaN  2.0 NaN\n",
      " |      1  2.0  3.0 NaN\n",
      " |      2  NaN  NaN 2.0\n",
      " |      3  3.0  NaN 2.0\n",
      " |      4  3.0  NaN 2.0\n",
      " |      \n",
      " |      >>> df.groupby(\"key\").fillna(method=\"bfill\")\n",
      " |           A    B   C\n",
      " |      0  2.0  2.0 NaN\n",
      " |      1  2.0  3.0 NaN\n",
      " |      2  3.0  NaN 2.0\n",
      " |      3  3.0  NaN NaN\n",
      " |      4  NaN  NaN NaN\n",
      " |      \n",
      " |      Propagate non-null values forward or backward within each group along rows.\n",
      " |      \n",
      " |      >>> df.T.groupby(np.array([0, 0, 1, 1])).fillna(method=\"ffill\").T\n",
      " |         key    A    B    C\n",
      " |      0  0.0  0.0  2.0  2.0\n",
      " |      1  0.0  2.0  3.0  3.0\n",
      " |      2  1.0  1.0  NaN  2.0\n",
      " |      3  1.0  3.0  NaN  NaN\n",
      " |      4  1.0  1.0  NaN  NaN\n",
      " |      \n",
      " |      >>> df.T.groupby(np.array([0, 0, 1, 1])).fillna(method=\"bfill\").T\n",
      " |         key    A    B    C\n",
      " |      0  0.0  NaN  2.0  NaN\n",
      " |      1  0.0  2.0  3.0  NaN\n",
      " |      2  1.0  NaN  2.0  2.0\n",
      " |      3  1.0  3.0  NaN  NaN\n",
      " |      4  1.0  NaN  NaN  NaN\n",
      " |      \n",
      " |      Only replace the first NaN element within a group along rows.\n",
      " |      \n",
      " |      >>> df.groupby(\"key\").fillna(method=\"ffill\", limit=1)\n",
      " |           A    B    C\n",
      " |      0  NaN  2.0  NaN\n",
      " |      1  2.0  3.0  NaN\n",
      " |      2  NaN  NaN  2.0\n",
      " |      3  3.0  NaN  2.0\n",
      " |      4  3.0  NaN  NaN\n",
      " |  \n",
      " |  filter(self, func, dropna: 'bool' = True, *args, **kwargs)\n",
      " |      Filter elements from groups that don't satisfy a criterion.\n",
      " |      \n",
      " |      Elements from groups are filtered if they do not satisfy the\n",
      " |      boolean criterion specified by func.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : function\n",
      " |          Criterion to apply to each group. Should return True or False.\n",
      " |      dropna : bool\n",
      " |          Drop groups that do not pass the filter. True by default; if False,\n",
      " |          groups that evaluate False are filled with NaNs.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Each subframe is endowed the attribute 'name' in case you need to know\n",
      " |      which group you are working on.\n",
      " |      \n",
      " |      Functions that mutate the passed object can produce unexpected\n",
      " |      behavior or errors and are not supported. See :ref:`gotchas.udf-mutation`\n",
      " |      for more details.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A' : ['foo', 'bar', 'foo', 'bar',\n",
      " |      ...                           'foo', 'bar'],\n",
      " |      ...                    'B' : [1, 2, 3, 4, 5, 6],\n",
      " |      ...                    'C' : [2.0, 5., 8., 1., 2., 9.]})\n",
      " |      >>> grouped = df.groupby('A')\n",
      " |      >>> grouped.filter(lambda x: x['B'].mean() > 3.)\n",
      " |           A  B    C\n",
      " |      1  bar  2  5.0\n",
      " |      3  bar  4  1.0\n",
      " |      5  bar  6  9.0\n",
      " |  \n",
      " |  hist(self, column: 'IndexLabel | None' = None, by=None, grid: 'bool' = True, xlabelsize: 'int | None' = None, xrot: 'float | None' = None, ylabelsize: 'int | None' = None, yrot: 'float | None' = None, ax=None, sharex: 'bool' = False, sharey: 'bool' = False, figsize: 'tuple[int, int] | None' = None, layout: 'tuple[int, int] | None' = None, bins: 'int | Sequence[int]' = 10, backend: 'str | None' = None, legend: 'bool' = False, **kwargs)\n",
      " |      Make a histogram of the DataFrame's columns.\n",
      " |      \n",
      " |      A `histogram`_ is a representation of the distribution of data.\n",
      " |      This function calls :meth:`matplotlib.pyplot.hist`, on each series in\n",
      " |      the DataFrame, resulting in one histogram per column.\n",
      " |      \n",
      " |      .. _histogram: https://en.wikipedia.org/wiki/Histogram\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      data : DataFrame\n",
      " |          The pandas object holding the data.\n",
      " |      column : str or sequence, optional\n",
      " |          If passed, will be used to limit data to a subset of columns.\n",
      " |      by : object, optional\n",
      " |          If passed, then used to form histograms for separate groups.\n",
      " |      grid : bool, default True\n",
      " |          Whether to show axis grid lines.\n",
      " |      xlabelsize : int, default None\n",
      " |          If specified changes the x-axis label size.\n",
      " |      xrot : float, default None\n",
      " |          Rotation of x axis labels. For example, a value of 90 displays the\n",
      " |          x labels rotated 90 degrees clockwise.\n",
      " |      ylabelsize : int, default None\n",
      " |          If specified changes the y-axis label size.\n",
      " |      yrot : float, default None\n",
      " |          Rotation of y axis labels. For example, a value of 90 displays the\n",
      " |          y labels rotated 90 degrees clockwise.\n",
      " |      ax : Matplotlib axes object, default None\n",
      " |          The axes to plot the histogram on.\n",
      " |      sharex : bool, default True if ax is None else False\n",
      " |          In case subplots=True, share x axis and set some x axis labels to\n",
      " |          invisible; defaults to True if ax is None otherwise False if an ax\n",
      " |          is passed in.\n",
      " |          Note that passing in both an ax and sharex=True will alter all x axis\n",
      " |          labels for all subplots in a figure.\n",
      " |      sharey : bool, default False\n",
      " |          In case subplots=True, share y axis and set some y axis labels to\n",
      " |          invisible.\n",
      " |      figsize : tuple, optional\n",
      " |          The size in inches of the figure to create. Uses the value in\n",
      " |          `matplotlib.rcParams` by default.\n",
      " |      layout : tuple, optional\n",
      " |          Tuple of (rows, columns) for the layout of the histograms.\n",
      " |      bins : int or sequence, default 10\n",
      " |          Number of histogram bins to be used. If an integer is given, bins + 1\n",
      " |          bin edges are calculated and returned. If bins is a sequence, gives\n",
      " |          bin edges, including left edge of first bin and right edge of last\n",
      " |          bin. In this case, bins is returned unmodified.\n",
      " |      \n",
      " |      backend : str, default None\n",
      " |          Backend to use instead of the backend specified in the option\n",
      " |          ``plotting.backend``. For instance, 'matplotlib'. Alternatively, to\n",
      " |          specify the ``plotting.backend`` for the whole session, set\n",
      " |          ``pd.options.plotting.backend``.\n",
      " |      \n",
      " |      legend : bool, default False\n",
      " |          Whether to show the legend.\n",
      " |      \n",
      " |      **kwargs\n",
      " |          All other plotting keyword arguments to be passed to\n",
      " |          :meth:`matplotlib.pyplot.hist`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      matplotlib.AxesSubplot or numpy.ndarray of them\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      matplotlib.pyplot.hist : Plot a histogram using matplotlib.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      This example draws a histogram based on the length and width of\n",
      " |      some animals, displayed in three bins\n",
      " |      \n",
      " |      .. plot::\n",
      " |          :context: close-figs\n",
      " |      \n",
      " |          >>> df = pd.DataFrame({\n",
      " |          ...     'length': [1.5, 0.5, 1.2, 0.9, 3],\n",
      " |          ...     'width': [0.7, 0.2, 0.15, 0.2, 1.1]\n",
      " |          ...     }, index=['pig', 'rabbit', 'duck', 'chicken', 'horse'])\n",
      " |          >>> hist = df.hist(bins=3)\n",
      " |  \n",
      " |  idxmax(self, axis: 'Axis | None | lib.NoDefault' = <no_default>, skipna: 'bool' = True, numeric_only: 'bool' = False) -> 'DataFrame'\n",
      " |      Return index of first occurrence of maximum over requested axis.\n",
      " |      \n",
      " |      NA/null values are excluded.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {{0 or 'index', 1 or 'columns'}}, default None\n",
      " |          The axis to use. 0 or 'index' for row-wise, 1 or 'columns' for column-wise.\n",
      " |          If axis is not provided, grouper's axis is used.\n",
      " |      \n",
      " |          .. versionchanged:: 2.0.0\n",
      " |      \n",
      " |          .. deprecated:: 2.1.0\n",
      " |              For axis=1, operate on the underlying object instead. Otherwise\n",
      " |              the axis keyword is not necessary.\n",
      " |      \n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      numeric_only : bool, default False\n",
      " |          Include only `float`, `int` or `boolean` data.\n",
      " |      \n",
      " |          .. versionadded:: 1.5.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Indexes of maxima along the specified axis.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError\n",
      " |          * If the row/column is empty\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.idxmax : Return index of the maximum element.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This method is the DataFrame version of ``ndarray.argmax``.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Consider a dataset containing food consumption in Argentina.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'consumption': [10.51, 103.11, 55.48],\n",
      " |      ...                    'co2_emissions': [37.2, 19.66, 1712]},\n",
      " |      ...                    index=['Pork', 'Wheat Products', 'Beef'])\n",
      " |      \n",
      " |      >>> df\n",
      " |                      consumption  co2_emissions\n",
      " |      Pork                  10.51         37.20\n",
      " |      Wheat Products       103.11         19.66\n",
      " |      Beef                  55.48       1712.00\n",
      " |      \n",
      " |      By default, it returns the index for the maximum value in each column.\n",
      " |      \n",
      " |      >>> df.idxmax()\n",
      " |      consumption     Wheat Products\n",
      " |      co2_emissions             Beef\n",
      " |      dtype: object\n",
      " |      \n",
      " |      To return the index for the maximum value in each row, use ``axis=\"columns\"``.\n",
      " |      \n",
      " |      >>> df.idxmax(axis=\"columns\")\n",
      " |      Pork              co2_emissions\n",
      " |      Wheat Products     consumption\n",
      " |      Beef              co2_emissions\n",
      " |      dtype: object\n",
      " |  \n",
      " |  idxmin(self, axis: 'Axis | None | lib.NoDefault' = <no_default>, skipna: 'bool' = True, numeric_only: 'bool' = False) -> 'DataFrame'\n",
      " |      Return index of first occurrence of minimum over requested axis.\n",
      " |      \n",
      " |      NA/null values are excluded.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {{0 or 'index', 1 or 'columns'}}, default None\n",
      " |          The axis to use. 0 or 'index' for row-wise, 1 or 'columns' for column-wise.\n",
      " |          If axis is not provided, grouper's axis is used.\n",
      " |      \n",
      " |          .. versionchanged:: 2.0.0\n",
      " |      \n",
      " |          .. deprecated:: 2.1.0\n",
      " |              For axis=1, operate on the underlying object instead. Otherwise\n",
      " |              the axis keyword is not necessary.\n",
      " |      \n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      numeric_only : bool, default False\n",
      " |          Include only `float`, `int` or `boolean` data.\n",
      " |      \n",
      " |          .. versionadded:: 1.5.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Indexes of minima along the specified axis.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError\n",
      " |          * If the row/column is empty\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.idxmin : Return index of the minimum element.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This method is the DataFrame version of ``ndarray.argmin``.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Consider a dataset containing food consumption in Argentina.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'consumption': [10.51, 103.11, 55.48],\n",
      " |      ...                    'co2_emissions': [37.2, 19.66, 1712]},\n",
      " |      ...                    index=['Pork', 'Wheat Products', 'Beef'])\n",
      " |      \n",
      " |      >>> df\n",
      " |                      consumption  co2_emissions\n",
      " |      Pork                  10.51         37.20\n",
      " |      Wheat Products       103.11         19.66\n",
      " |      Beef                  55.48       1712.00\n",
      " |      \n",
      " |      By default, it returns the index for the minimum value in each column.\n",
      " |      \n",
      " |      >>> df.idxmin()\n",
      " |      consumption                Pork\n",
      " |      co2_emissions    Wheat Products\n",
      " |      dtype: object\n",
      " |      \n",
      " |      To return the index for the minimum value in each row, use ``axis=\"columns\"``.\n",
      " |      \n",
      " |      >>> df.idxmin(axis=\"columns\")\n",
      " |      Pork                consumption\n",
      " |      Wheat Products    co2_emissions\n",
      " |      Beef                consumption\n",
      " |      dtype: object\n",
      " |  \n",
      " |  nunique(self, dropna: 'bool' = True) -> 'DataFrame'\n",
      " |      Return DataFrame with counts of unique elements in each position.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dropna : bool, default True\n",
      " |          Don't include NaN in the counts.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      nunique: DataFrame\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'id': ['spam', 'egg', 'egg', 'spam',\n",
      " |      ...                           'ham', 'ham'],\n",
      " |      ...                    'value1': [1, 5, 5, 2, 5, 5],\n",
      " |      ...                    'value2': list('abbaxy')})\n",
      " |      >>> df\n",
      " |           id  value1 value2\n",
      " |      0  spam       1      a\n",
      " |      1   egg       5      b\n",
      " |      2   egg       5      b\n",
      " |      3  spam       2      a\n",
      " |      4   ham       5      x\n",
      " |      5   ham       5      y\n",
      " |      \n",
      " |      >>> df.groupby('id').nunique()\n",
      " |            value1  value2\n",
      " |      id\n",
      " |      egg        1       1\n",
      " |      ham        1       2\n",
      " |      spam       2       1\n",
      " |      \n",
      " |      Check for rows with the same id but conflicting values:\n",
      " |      \n",
      " |      >>> df.groupby('id').filter(lambda g: (g.nunique() > 1).any())\n",
      " |           id  value1 value2\n",
      " |      0  spam       1      a\n",
      " |      3  spam       2      a\n",
      " |      4   ham       5      x\n",
      " |      5   ham       5      y\n",
      " |  \n",
      " |  skew(self, axis: 'Axis | None | lib.NoDefault' = <no_default>, skipna: 'bool' = True, numeric_only: 'bool' = False, **kwargs) -> 'DataFrame'\n",
      " |      Return unbiased skew within groups.\n",
      " |      \n",
      " |      Normalized by N-1.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns', None}, default 0\n",
      " |          Axis for the function to be applied on.\n",
      " |      \n",
      " |          Specifying ``axis=None`` will apply the aggregation across both axes.\n",
      " |      \n",
      " |          .. versionadded:: 2.0.0\n",
      " |      \n",
      " |          .. deprecated:: 2.1.0\n",
      " |              For axis=1, operate on the underlying object instead. Otherwise\n",
      " |              the axis keyword is not necessary.\n",
      " |      \n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      \n",
      " |      numeric_only : bool, default False\n",
      " |          Include only float, int, boolean columns.\n",
      " |      \n",
      " |      **kwargs\n",
      " |          Additional keyword arguments to be passed to the function.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.skew : Return unbiased skew over requested axis.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> arrays = [['falcon', 'parrot', 'cockatoo', 'kiwi',\n",
      " |      ...            'lion', 'monkey', 'rabbit'],\n",
      " |      ...           ['bird', 'bird', 'bird', 'bird',\n",
      " |      ...            'mammal', 'mammal', 'mammal']]\n",
      " |      >>> index = pd.MultiIndex.from_arrays(arrays, names=('name', 'class'))\n",
      " |      >>> df = pd.DataFrame({'max_speed': [389.0, 24.0, 70.0, np.nan,\n",
      " |      ...                                  80.5, 21.5, 15.0]},\n",
      " |      ...                   index=index)\n",
      " |      >>> df\n",
      " |                      max_speed\n",
      " |      name     class\n",
      " |      falcon   bird        389.0\n",
      " |      parrot   bird         24.0\n",
      " |      cockatoo bird         70.0\n",
      " |      kiwi     bird          NaN\n",
      " |      lion     mammal       80.5\n",
      " |      monkey   mammal       21.5\n",
      " |      rabbit   mammal       15.0\n",
      " |      >>> gb = df.groupby([\"class\"])\n",
      " |      >>> gb.skew()\n",
      " |              max_speed\n",
      " |      class\n",
      " |      bird     1.628296\n",
      " |      mammal   1.669046\n",
      " |      >>> gb.skew(skipna=False)\n",
      " |              max_speed\n",
      " |      class\n",
      " |      bird          NaN\n",
      " |      mammal   1.669046\n",
      " |  \n",
      " |  take(self, indices: 'TakeIndexer', axis: 'Axis | None | lib.NoDefault' = <no_default>, **kwargs) -> 'DataFrame'\n",
      " |      Return the elements in the given *positional* indices in each group.\n",
      " |      \n",
      " |      This means that we are not indexing according to actual values in\n",
      " |      the index attribute of the object. We are indexing according to the\n",
      " |      actual position of the element in the object.\n",
      " |      \n",
      " |      If a requested index does not exist for some group, this method will raise.\n",
      " |      To get similar behavior that ignores indices that don't exist, see\n",
      " |      :meth:`.DataFrameGroupBy.nth`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      indices : array-like\n",
      " |          An array of ints indicating which positions to take.\n",
      " |      axis : {0 or 'index', 1 or 'columns', None}, default 0\n",
      " |          The axis on which to select elements. ``0`` means that we are\n",
      " |          selecting rows, ``1`` means that we are selecting columns.\n",
      " |      \n",
      " |          .. deprecated:: 2.1.0\n",
      " |              For axis=1, operate on the underlying object instead. Otherwise\n",
      " |              the axis keyword is not necessary.\n",
      " |      \n",
      " |      **kwargs\n",
      " |          For compatibility with :meth:`numpy.take`. Has no effect on the\n",
      " |          output.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          An DataFrame containing the elements taken from each group.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.take : Take elements from a Series along an axis.\n",
      " |      DataFrame.loc : Select a subset of a DataFrame by labels.\n",
      " |      DataFrame.iloc : Select a subset of a DataFrame by positions.\n",
      " |      numpy.take : Take elements from an array along an axis.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([('falcon', 'bird', 389.0),\n",
      " |      ...                    ('parrot', 'bird', 24.0),\n",
      " |      ...                    ('lion', 'mammal', 80.5),\n",
      " |      ...                    ('monkey', 'mammal', np.nan),\n",
      " |      ...                    ('rabbit', 'mammal', 15.0)],\n",
      " |      ...                   columns=['name', 'class', 'max_speed'],\n",
      " |      ...                   index=[4, 3, 2, 1, 0])\n",
      " |      >>> df\n",
      " |           name   class  max_speed\n",
      " |      4  falcon    bird      389.0\n",
      " |      3  parrot    bird       24.0\n",
      " |      2    lion  mammal       80.5\n",
      " |      1  monkey  mammal        NaN\n",
      " |      0  rabbit  mammal       15.0\n",
      " |      >>> gb = df.groupby([1, 1, 2, 2, 2])\n",
      " |      \n",
      " |      Take elements at positions 0 and 1 along the axis 0 (default).\n",
      " |      \n",
      " |      Note how the indices selected in the result do not correspond to\n",
      " |      our input indices 0 and 1. That's because we are selecting the 0th\n",
      " |      and 1st rows, not rows whose indices equal 0 and 1.\n",
      " |      \n",
      " |      >>> gb.take([0, 1])\n",
      " |             name   class  max_speed\n",
      " |      1 4  falcon    bird      389.0\n",
      " |        3  parrot    bird       24.0\n",
      " |      2 2    lion  mammal       80.5\n",
      " |        1  monkey  mammal        NaN\n",
      " |      \n",
      " |      The order of the specified indices influences the order in the result.\n",
      " |      Here, the order is swapped from the previous example.\n",
      " |      \n",
      " |      >>> gb.take([1, 0])\n",
      " |             name   class  max_speed\n",
      " |      1 3  parrot    bird       24.0\n",
      " |        4  falcon    bird      389.0\n",
      " |      2 1  monkey  mammal        NaN\n",
      " |        2    lion  mammal       80.5\n",
      " |      \n",
      " |      Take elements at indices 1 and 2 along the axis 1 (column selection).\n",
      " |      \n",
      " |      We may take elements using negative integers for positive indices,\n",
      " |      starting from the end of the object, just like with Python lists.\n",
      " |      \n",
      " |      >>> gb.take([-1, -2])\n",
      " |             name   class  max_speed\n",
      " |      1 3  parrot    bird       24.0\n",
      " |        4  falcon    bird      389.0\n",
      " |      2 0  rabbit  mammal       15.0\n",
      " |        1  monkey  mammal        NaN\n",
      " |  \n",
      " |  transform(self, func, *args, engine=None, engine_kwargs=None, **kwargs)\n",
      " |      Call function producing a same-indexed DataFrame on each group.\n",
      " |      \n",
      " |      Returns a DataFrame having the same indexes as the original object\n",
      " |      filled with the transformed values.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      f : function, str\n",
      " |          Function to apply to each group. See the Notes section below for requirements.\n",
      " |      \n",
      " |          Accepted inputs are:\n",
      " |      \n",
      " |          - String\n",
      " |          - Python function\n",
      " |          - Numba JIT function with ``engine='numba'`` specified.\n",
      " |      \n",
      " |          Only passing a single function is supported with this engine.\n",
      " |          If the ``'numba'`` engine is chosen, the function must be\n",
      " |          a user defined function with ``values`` and ``index`` as the\n",
      " |          first and second arguments respectively in the function signature.\n",
      " |          Each group's index will be passed to the user defined function\n",
      " |          and optionally available for use.\n",
      " |      \n",
      " |          If a string is chosen, then it needs to be the name\n",
      " |          of the groupby method you want to use.\n",
      " |      *args\n",
      " |          Positional arguments to pass to func.\n",
      " |      engine : str, default None\n",
      " |          * ``'cython'`` : Runs the function through C-extensions from cython.\n",
      " |          * ``'numba'`` : Runs the function through JIT compiled code from numba.\n",
      " |          * ``None`` : Defaults to ``'cython'`` or the global setting ``compute.use_numba``\n",
      " |      \n",
      " |      engine_kwargs : dict, default None\n",
      " |          * For ``'cython'`` engine, there are no accepted ``engine_kwargs``\n",
      " |          * For ``'numba'`` engine, the engine can accept ``nopython``, ``nogil``\n",
      " |            and ``parallel`` dictionary keys. The values must either be ``True`` or\n",
      " |            ``False``. The default ``engine_kwargs`` for the ``'numba'`` engine is\n",
      " |            ``{'nopython': True, 'nogil': False, 'parallel': False}`` and will be\n",
      " |            applied to the function\n",
      " |      \n",
      " |      **kwargs\n",
      " |          Keyword arguments to be passed into func.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.groupby.apply : Apply function ``func`` group-wise and combine\n",
      " |          the results together.\n",
      " |      DataFrame.groupby.aggregate : Aggregate using one or more\n",
      " |          operations over the specified axis.\n",
      " |      DataFrame.transform : Call ``func`` on self producing a DataFrame with the\n",
      " |          same axis shape as self.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Each group is endowed the attribute 'name' in case you need to know\n",
      " |      which group you are working on.\n",
      " |      \n",
      " |      The current implementation imposes three requirements on f:\n",
      " |      \n",
      " |      * f must return a value that either has the same shape as the input\n",
      " |        subframe or can be broadcast to the shape of the input subframe.\n",
      " |        For example, if `f` returns a scalar it will be broadcast to have the\n",
      " |        same shape as the input subframe.\n",
      " |      * if this is a DataFrame, f must support application column-by-column\n",
      " |        in the subframe. If f also supports application to the entire subframe,\n",
      " |        then a fast path is used starting from the second chunk.\n",
      " |      * f must not mutate groups. Mutation is not supported and may\n",
      " |        produce unexpected results. See :ref:`gotchas.udf-mutation` for more details.\n",
      " |      \n",
      " |      When using ``engine='numba'``, there will be no \"fall back\" behavior internally.\n",
      " |      The group data and group index will be passed as numpy arrays to the JITed\n",
      " |      user defined function, and no alternative execution attempts will be tried.\n",
      " |      \n",
      " |      .. versionchanged:: 1.3.0\n",
      " |      \n",
      " |          The resulting dtype will reflect the return value of the passed ``func``,\n",
      " |          see the examples below.\n",
      " |      \n",
      " |      .. versionchanged:: 2.0.0\n",
      " |      \n",
      " |          When using ``.transform`` on a grouped DataFrame and the transformation function\n",
      " |          returns a DataFrame, pandas now aligns the result's index\n",
      " |          with the input's index. You can call ``.to_numpy()`` on the\n",
      " |          result of the transformation function to avoid alignment.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A' : ['foo', 'bar', 'foo', 'bar',\n",
      " |      ...                           'foo', 'bar'],\n",
      " |      ...                    'B' : ['one', 'one', 'two', 'three',\n",
      " |      ...                           'two', 'two'],\n",
      " |      ...                    'C' : [1, 5, 5, 2, 5, 5],\n",
      " |      ...                    'D' : [2.0, 5., 8., 1., 2., 9.]})\n",
      " |      >>> grouped = df.groupby('A')[['C', 'D']]\n",
      " |      >>> grouped.transform(lambda x: (x - x.mean()) / x.std())\n",
      " |              C         D\n",
      " |      0 -1.154701 -0.577350\n",
      " |      1  0.577350  0.000000\n",
      " |      2  0.577350  1.154701\n",
      " |      3 -1.154701 -1.000000\n",
      " |      4  0.577350 -0.577350\n",
      " |      5  0.577350  1.000000\n",
      " |      \n",
      " |      Broadcast result of the transformation\n",
      " |      \n",
      " |      >>> grouped.transform(lambda x: x.max() - x.min())\n",
      " |          C    D\n",
      " |      0  4.0  6.0\n",
      " |      1  3.0  8.0\n",
      " |      2  4.0  6.0\n",
      " |      3  3.0  8.0\n",
      " |      4  4.0  6.0\n",
      " |      5  3.0  8.0\n",
      " |      \n",
      " |      >>> grouped.transform(\"mean\")\n",
      " |          C    D\n",
      " |      0  3.666667  4.0\n",
      " |      1  4.000000  5.0\n",
      " |      2  3.666667  4.0\n",
      " |      3  4.000000  5.0\n",
      " |      4  3.666667  4.0\n",
      " |      5  4.000000  5.0\n",
      " |      \n",
      " |      .. versionchanged:: 1.3.0\n",
      " |      \n",
      " |      The resulting dtype will reflect the return value of the passed ``func``,\n",
      " |      for example:\n",
      " |      \n",
      " |      >>> grouped.transform(lambda x: x.astype(int).max())\n",
      " |      C  D\n",
      " |      0  5  8\n",
      " |      1  5  9\n",
      " |      2  5  8\n",
      " |      3  5  9\n",
      " |      4  5  8\n",
      " |      5  5  9\n",
      " |  \n",
      " |  value_counts(self, subset: 'Sequence[Hashable] | None' = None, normalize: 'bool' = False, sort: 'bool' = True, ascending: 'bool' = False, dropna: 'bool' = True) -> 'DataFrame | Series'\n",
      " |      Return a Series or DataFrame containing counts of unique rows.\n",
      " |      \n",
      " |      .. versionadded:: 1.4.0\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      subset : list-like, optional\n",
      " |          Columns to use when counting unique combinations.\n",
      " |      normalize : bool, default False\n",
      " |          Return proportions rather than frequencies.\n",
      " |      sort : bool, default True\n",
      " |          Sort by frequencies.\n",
      " |      ascending : bool, default False\n",
      " |          Sort in ascending order.\n",
      " |      dropna : bool, default True\n",
      " |          Don't include counts of rows that contain NA values.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Series if the groupby as_index is True, otherwise DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.value_counts: Equivalent method on Series.\n",
      " |      DataFrame.value_counts: Equivalent method on DataFrame.\n",
      " |      SeriesGroupBy.value_counts: Equivalent method on SeriesGroupBy.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      - If the groupby as_index is True then the returned Series will have a\n",
      " |        MultiIndex with one level per input column.\n",
      " |      - If the groupby as_index is False then the returned DataFrame will have an\n",
      " |        additional column with the value_counts. The column is labelled 'count' or\n",
      " |        'proportion', depending on the ``normalize`` parameter.\n",
      " |      \n",
      " |      By default, rows that contain any NA values are omitted from\n",
      " |      the result.\n",
      " |      \n",
      " |      By default, the result will be in descending order so that the\n",
      " |      first element of each group is the most frequently-occurring row.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({\n",
      " |      ...    'gender': ['male', 'male', 'female', 'male', 'female', 'male'],\n",
      " |      ...    'education': ['low', 'medium', 'high', 'low', 'high', 'low'],\n",
      " |      ...    'country': ['US', 'FR', 'US', 'FR', 'FR', 'FR']\n",
      " |      ... })\n",
      " |      \n",
      " |      >>> df\n",
      " |              gender  education   country\n",
      " |      0       male    low         US\n",
      " |      1       male    medium      FR\n",
      " |      2       female  high        US\n",
      " |      3       male    low         FR\n",
      " |      4       female  high        FR\n",
      " |      5       male    low         FR\n",
      " |      \n",
      " |      >>> df.groupby('gender').value_counts()\n",
      " |      gender  education  country\n",
      " |      female  high       FR         1\n",
      " |                         US         1\n",
      " |      male    low        FR         2\n",
      " |                         US         1\n",
      " |              medium     FR         1\n",
      " |      Name: count, dtype: int64\n",
      " |      \n",
      " |      >>> df.groupby('gender').value_counts(ascending=True)\n",
      " |      gender  education  country\n",
      " |      female  high       FR         1\n",
      " |                         US         1\n",
      " |      male    low        US         1\n",
      " |              medium     FR         1\n",
      " |              low        FR         2\n",
      " |      Name: count, dtype: int64\n",
      " |      \n",
      " |      >>> df.groupby('gender').value_counts(normalize=True)\n",
      " |      gender  education  country\n",
      " |      female  high       FR         0.50\n",
      " |                         US         0.50\n",
      " |      male    low        FR         0.50\n",
      " |                         US         0.25\n",
      " |              medium     FR         0.25\n",
      " |      Name: proportion, dtype: float64\n",
      " |      \n",
      " |      >>> df.groupby('gender', as_index=False).value_counts()\n",
      " |         gender education country  count\n",
      " |      0  female      high      FR      1\n",
      " |      1  female      high      US      1\n",
      " |      2    male       low      FR      2\n",
      " |      3    male       low      US      1\n",
      " |      4    male    medium      FR      1\n",
      " |      \n",
      " |      >>> df.groupby('gender', as_index=False).value_counts(normalize=True)\n",
      " |         gender education country  proportion\n",
      " |      0  female      high      FR        0.50\n",
      " |      1  female      high      US        0.50\n",
      " |      2    male       low      FR        0.50\n",
      " |      3    male       low      US        0.25\n",
      " |      4    male    medium      FR        0.25\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties defined here:\n",
      " |  \n",
      " |  dtypes\n",
      " |      Return the dtypes in the DataFrame.\n",
      " |      \n",
      " |      This returns a Series with the data type of each column.\n",
      " |      The result's index is the original DataFrame's columns. Columns\n",
      " |      with mixed types are stored with the ``object`` dtype. See\n",
      " |      :ref:`the User Guide <basics.dtypes>` for more.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      pandas.Series\n",
      " |          The data type of each column.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'float': [1.0],\n",
      " |      ...                    'int': [1],\n",
      " |      ...                    'datetime': [pd.Timestamp('20180310')],\n",
      " |      ...                    'string': ['foo']})\n",
      " |      >>> df.dtypes\n",
      " |      float              float64\n",
      " |      int                  int64\n",
      " |      datetime    datetime64[ns]\n",
      " |      string              object\n",
      " |      dtype: object\n",
      " |  \n",
      " |  plot\n",
      " |      Make plots of Series or DataFrame.\n",
      " |      \n",
      " |      Uses the backend specified by the\n",
      " |      option ``plotting.backend``. By default, matplotlib is used.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      data : Series or DataFrame\n",
      " |          The object for which the method is called.\n",
      " |      x : label or position, default None\n",
      " |          Only used if data is a DataFrame.\n",
      " |      y : label, position or list of label, positions, default None\n",
      " |          Allows plotting of one column versus another. Only used if data is a\n",
      " |          DataFrame.\n",
      " |      kind : str\n",
      " |          The kind of plot to produce:\n",
      " |      \n",
      " |          - 'line' : line plot (default)\n",
      " |          - 'bar' : vertical bar plot\n",
      " |          - 'barh' : horizontal bar plot\n",
      " |          - 'hist' : histogram\n",
      " |          - 'box' : boxplot\n",
      " |          - 'kde' : Kernel Density Estimation plot\n",
      " |          - 'density' : same as 'kde'\n",
      " |          - 'area' : area plot\n",
      " |          - 'pie' : pie plot\n",
      " |          - 'scatter' : scatter plot (DataFrame only)\n",
      " |          - 'hexbin' : hexbin plot (DataFrame only)\n",
      " |      ax : matplotlib axes object, default None\n",
      " |          An axes of the current figure.\n",
      " |      subplots : bool or sequence of iterables, default False\n",
      " |          Whether to group columns into subplots:\n",
      " |      \n",
      " |          - ``False`` : No subplots will be used\n",
      " |          - ``True`` : Make separate subplots for each column.\n",
      " |          - sequence of iterables of column labels: Create a subplot for each\n",
      " |            group of columns. For example `[('a', 'c'), ('b', 'd')]` will\n",
      " |            create 2 subplots: one with columns 'a' and 'c', and one\n",
      " |            with columns 'b' and 'd'. Remaining columns that aren't specified\n",
      " |            will be plotted in additional subplots (one per column).\n",
      " |      \n",
      " |            .. versionadded:: 1.5.0\n",
      " |      \n",
      " |      sharex : bool, default True if ax is None else False\n",
      " |          In case ``subplots=True``, share x axis and set some x axis labels\n",
      " |          to invisible; defaults to True if ax is None otherwise False if\n",
      " |          an ax is passed in; Be aware, that passing in both an ax and\n",
      " |          ``sharex=True`` will alter all x axis labels for all axis in a figure.\n",
      " |      sharey : bool, default False\n",
      " |          In case ``subplots=True``, share y axis and set some y axis labels to invisible.\n",
      " |      layout : tuple, optional\n",
      " |          (rows, columns) for the layout of subplots.\n",
      " |      figsize : a tuple (width, height) in inches\n",
      " |          Size of a figure object.\n",
      " |      use_index : bool, default True\n",
      " |          Use index as ticks for x axis.\n",
      " |      title : str or list\n",
      " |          Title to use for the plot. If a string is passed, print the string\n",
      " |          at the top of the figure. If a list is passed and `subplots` is\n",
      " |          True, print each item in the list above the corresponding subplot.\n",
      " |      grid : bool, default None (matlab style default)\n",
      " |          Axis grid lines.\n",
      " |      legend : bool or {'reverse'}\n",
      " |          Place legend on axis subplots.\n",
      " |      style : list or dict\n",
      " |          The matplotlib line style per column.\n",
      " |      logx : bool or 'sym', default False\n",
      " |          Use log scaling or symlog scaling on x axis.\n",
      " |      \n",
      " |      logy : bool or 'sym' default False\n",
      " |          Use log scaling or symlog scaling on y axis.\n",
      " |      \n",
      " |      loglog : bool or 'sym', default False\n",
      " |          Use log scaling or symlog scaling on both x and y axes.\n",
      " |      \n",
      " |      xticks : sequence\n",
      " |          Values to use for the xticks.\n",
      " |      yticks : sequence\n",
      " |          Values to use for the yticks.\n",
      " |      xlim : 2-tuple/list\n",
      " |          Set the x limits of the current axes.\n",
      " |      ylim : 2-tuple/list\n",
      " |          Set the y limits of the current axes.\n",
      " |      xlabel : label, optional\n",
      " |          Name to use for the xlabel on x-axis. Default uses index name as xlabel, or the\n",
      " |          x-column name for planar plots.\n",
      " |      \n",
      " |          .. versionchanged:: 1.2.0\n",
      " |      \n",
      " |             Now applicable to planar plots (`scatter`, `hexbin`).\n",
      " |      \n",
      " |          .. versionchanged:: 2.0.0\n",
      " |      \n",
      " |              Now applicable to histograms.\n",
      " |      \n",
      " |      ylabel : label, optional\n",
      " |          Name to use for the ylabel on y-axis. Default will show no ylabel, or the\n",
      " |          y-column name for planar plots.\n",
      " |      \n",
      " |          .. versionchanged:: 1.2.0\n",
      " |      \n",
      " |             Now applicable to planar plots (`scatter`, `hexbin`).\n",
      " |      \n",
      " |          .. versionchanged:: 2.0.0\n",
      " |      \n",
      " |              Now applicable to histograms.\n",
      " |      \n",
      " |      rot : float, default None\n",
      " |          Rotation for ticks (xticks for vertical, yticks for horizontal\n",
      " |          plots).\n",
      " |      fontsize : float, default None\n",
      " |          Font size for xticks and yticks.\n",
      " |      colormap : str or matplotlib colormap object, default None\n",
      " |          Colormap to select colors from. If string, load colormap with that\n",
      " |          name from matplotlib.\n",
      " |      colorbar : bool, optional\n",
      " |          If True, plot colorbar (only relevant for 'scatter' and 'hexbin'\n",
      " |          plots).\n",
      " |      position : float\n",
      " |          Specify relative alignments for bar plot layout.\n",
      " |          From 0 (left/bottom-end) to 1 (right/top-end). Default is 0.5\n",
      " |          (center).\n",
      " |      table : bool, Series or DataFrame, default False\n",
      " |          If True, draw a table using the data in the DataFrame and the data\n",
      " |          will be transposed to meet matplotlib's default layout.\n",
      " |          If a Series or DataFrame is passed, use passed data to draw a\n",
      " |          table.\n",
      " |      yerr : DataFrame, Series, array-like, dict and str\n",
      " |          See :ref:`Plotting with Error Bars <visualization.errorbars>` for\n",
      " |          detail.\n",
      " |      xerr : DataFrame, Series, array-like, dict and str\n",
      " |          Equivalent to yerr.\n",
      " |      stacked : bool, default False in line and bar plots, and True in area plot\n",
      " |          If True, create stacked plot.\n",
      " |      secondary_y : bool or sequence, default False\n",
      " |          Whether to plot on the secondary y-axis if a list/tuple, which\n",
      " |          columns to plot on secondary y-axis.\n",
      " |      mark_right : bool, default True\n",
      " |          When using a secondary_y axis, automatically mark the column\n",
      " |          labels with \"(right)\" in the legend.\n",
      " |      include_bool : bool, default is False\n",
      " |          If True, boolean values can be plotted.\n",
      " |      backend : str, default None\n",
      " |          Backend to use instead of the backend specified in the option\n",
      " |          ``plotting.backend``. For instance, 'matplotlib'. Alternatively, to\n",
      " |          specify the ``plotting.backend`` for the whole session, set\n",
      " |          ``pd.options.plotting.backend``.\n",
      " |      **kwargs\n",
      " |          Options to pass to matplotlib plotting method.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      :class:`matplotlib.axes.Axes` or numpy.ndarray of them\n",
      " |          If the backend is not the default matplotlib one, the return value\n",
      " |          will be the object returned by the backend.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      - See matplotlib documentation online for more on this subject\n",
      " |      - If `kind` = 'bar' or 'barh', you can specify relative alignments\n",
      " |        for bar plot layout by `position` keyword.\n",
      " |        From 0 (left/bottom-end) to 1 (right/top-end). Default is 0.5\n",
      " |        (center)\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      For Series:\n",
      " |      \n",
      " |      .. plot::\n",
      " |          :context: close-figs\n",
      " |      \n",
      " |          >>> ser = pd.Series([1, 2, 3, 3])\n",
      " |          >>> plot = ser.plot(kind='hist', title=\"My plot\")\n",
      " |      \n",
      " |      For DataFrame:\n",
      " |      \n",
      " |      .. plot::\n",
      " |          :context: close-figs\n",
      " |      \n",
      " |          >>> df = pd.DataFrame({'length': [1.5, 0.5, 1.2, 0.9, 3],\n",
      " |          ...                   'width': [0.7, 0.2, 0.15, 0.2, 1.1]},\n",
      " |          ...                   index=['pig', 'rabbit', 'duck', 'chicken', 'horse'])\n",
      " |          >>> plot = df.plot(title=\"DataFrame Plot\")\n",
      " |      \n",
      " |      For SeriesGroupBy:\n",
      " |      \n",
      " |      .. plot::\n",
      " |          :context: close-figs\n",
      " |      \n",
      " |          >>> lst = [-1, -2, -3, 1, 2, 3]\n",
      " |          >>> ser = pd.Series([1, 2, 2, 4, 6, 6], index=lst)\n",
      " |          >>> plot = ser.groupby(lambda x: x > 0).plot(title=\"SeriesGroupBy Plot\")\n",
      " |      \n",
      " |      For DataFrameGroupBy:\n",
      " |      \n",
      " |      .. plot::\n",
      " |          :context: close-figs\n",
      " |      \n",
      " |          >>> df = pd.DataFrame({\"col1\" : [1, 2, 3, 4],\n",
      " |          ...                   \"col2\" : [\"A\", \"B\", \"A\", \"B\"]})\n",
      " |          >>> plot = df.groupby(\"col2\").plot(kind=\"bar\", title=\"DataFrameGroupBy Plot\")\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __annotations__ = {}\n",
      " |  \n",
      " |  __orig_bases__ = (pandas.core.groupby.groupby.GroupBy[pandas.core.fram...\n",
      " |  \n",
      " |  __parameters__ = ()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.groupby.groupby.GroupBy:\n",
      " |  \n",
      " |  __getattr__(self, attr: 'str')\n",
      " |  \n",
      " |  __init__(self, obj: 'NDFrameT', keys: '_KeysArgType | None' = None, axis: 'Axis' = 0, level: 'IndexLabel | None' = None, grouper: 'ops.BaseGrouper | None' = None, exclusions: 'frozenset[Hashable] | None' = None, selection: 'IndexLabel | None' = None, as_index: 'bool' = True, sort: 'bool' = True, group_keys: 'bool' = True, observed: 'bool | lib.NoDefault' = <no_default>, dropna: 'bool' = True) -> 'None'\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  all(self, skipna: 'bool' = True)\n",
      " |      Return True if all values in the group are truthful, else False.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      skipna : bool, default True\n",
      " |          Flag to ignore nan values during truth testing.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          DataFrame or Series of boolean values, where a value is True if all elements\n",
      " |          are True within its respective group, False otherwise.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.groupby : Apply a function groupby to a Series.\n",
      " |      DataFrame.groupby : Apply a function groupby\n",
      " |          to each row or column of a DataFrame.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      For SeriesGroupBy:\n",
      " |      \n",
      " |      >>> lst = ['a', 'a', 'b']\n",
      " |      >>> ser = pd.Series([1, 2, 0], index=lst)\n",
      " |      >>> ser\n",
      " |      a    1\n",
      " |      a    2\n",
      " |      b    0\n",
      " |      dtype: int64\n",
      " |      >>> ser.groupby(level=0).all()\n",
      " |      a     True\n",
      " |      b    False\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      For DataFrameGroupBy:\n",
      " |      \n",
      " |      >>> data = [[1, 0, 3], [1, 5, 6], [7, 8, 9]]\n",
      " |      >>> df = pd.DataFrame(data, columns=[\"a\", \"b\", \"c\"],\n",
      " |      ...                   index=[\"ostrich\", \"penguin\", \"parrot\"])\n",
      " |      >>> df\n",
      " |               a  b  c\n",
      " |      ostrich  1  0  3\n",
      " |      penguin  1  5  6\n",
      " |      parrot   7  8  9\n",
      " |      >>> df.groupby(by=[\"a\"]).all()\n",
      " |             b      c\n",
      " |      a\n",
      " |      1  False   True\n",
      " |      7   True   True\n",
      " |  \n",
      " |  any(self, skipna: 'bool' = True)\n",
      " |      Return True if any value in the group is truthful, else False.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      skipna : bool, default True\n",
      " |          Flag to ignore nan values during truth testing.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          DataFrame or Series of boolean values, where a value is True if any element\n",
      " |          is True within its respective group, False otherwise.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.groupby : Apply a function groupby to a Series.\n",
      " |      DataFrame.groupby : Apply a function groupby\n",
      " |          to each row or column of a DataFrame.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      For SeriesGroupBy:\n",
      " |      \n",
      " |      >>> lst = ['a', 'a', 'b']\n",
      " |      >>> ser = pd.Series([1, 2, 0], index=lst)\n",
      " |      >>> ser\n",
      " |      a    1\n",
      " |      a    2\n",
      " |      b    0\n",
      " |      dtype: int64\n",
      " |      >>> ser.groupby(level=0).any()\n",
      " |      a     True\n",
      " |      b    False\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      For DataFrameGroupBy:\n",
      " |      \n",
      " |      >>> data = [[1, 0, 3], [1, 0, 6], [7, 1, 9]]\n",
      " |      >>> df = pd.DataFrame(data, columns=[\"a\", \"b\", \"c\"],\n",
      " |      ...                   index=[\"ostrich\", \"penguin\", \"parrot\"])\n",
      " |      >>> df\n",
      " |               a  b  c\n",
      " |      ostrich  1  0  3\n",
      " |      penguin  1  0  6\n",
      " |      parrot   7  1  9\n",
      " |      >>> df.groupby(by=[\"a\"]).any()\n",
      " |             b      c\n",
      " |      a\n",
      " |      1  False   True\n",
      " |      7   True   True\n",
      " |  \n",
      " |  apply(self, func, *args, **kwargs) -> 'NDFrameT'\n",
      " |      Apply function ``func`` group-wise and combine the results together.\n",
      " |      \n",
      " |      The function passed to ``apply`` must take a dataframe as its first\n",
      " |      argument and return a DataFrame, Series or scalar. ``apply`` will\n",
      " |      then take care of combining the results back together into a single\n",
      " |      dataframe or series. ``apply`` is therefore a highly flexible\n",
      " |      grouping method.\n",
      " |      \n",
      " |      While ``apply`` is a very flexible method, its downside is that\n",
      " |      using it can be quite a bit slower than using more specific methods\n",
      " |      like ``agg`` or ``transform``. Pandas offers a wide range of method that will\n",
      " |      be much faster than using ``apply`` for their specific purposes, so try to\n",
      " |      use them before reaching for ``apply``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : callable\n",
      " |          A callable that takes a dataframe as its first argument, and\n",
      " |          returns a dataframe, a series or a scalar. In addition the\n",
      " |          callable may take positional and keyword arguments.\n",
      " |      args, kwargs : tuple and dict\n",
      " |          Optional positional and keyword arguments to pass to ``func``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pipe : Apply function to the full GroupBy object instead of to each\n",
      " |          group.\n",
      " |      aggregate : Apply aggregate function to the GroupBy object.\n",
      " |      transform : Apply function column-by-column to the GroupBy object.\n",
      " |      Series.apply : Apply a function to a Series.\n",
      " |      DataFrame.apply : Apply a function to each row or column of a DataFrame.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      \n",
      " |      .. versionchanged:: 1.3.0\n",
      " |      \n",
      " |          The resulting dtype will reflect the return value of the passed ``func``,\n",
      " |          see the examples below.\n",
      " |      \n",
      " |      Functions that mutate the passed object can produce unexpected\n",
      " |      behavior or errors and are not supported. See :ref:`gotchas.udf-mutation`\n",
      " |      for more details.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A': 'a a b'.split(),\n",
      " |      ...                    'B': [1,2,3],\n",
      " |      ...                    'C': [4,6,5]})\n",
      " |      >>> g1 = df.groupby('A', group_keys=False)\n",
      " |      >>> g2 = df.groupby('A', group_keys=True)\n",
      " |      \n",
      " |      Notice that ``g1`` and ``g2`` have two groups, ``a`` and ``b``, and only\n",
      " |      differ in their ``group_keys`` argument. Calling `apply` in various ways,\n",
      " |      we can get different grouping results:\n",
      " |      \n",
      " |      Example 1: below the function passed to `apply` takes a DataFrame as\n",
      " |      its argument and returns a DataFrame. `apply` combines the result for\n",
      " |      each group together into a new DataFrame:\n",
      " |      \n",
      " |      >>> g1[['B', 'C']].apply(lambda x: x / x.sum())\n",
      " |                B    C\n",
      " |      0  0.333333  0.4\n",
      " |      1  0.666667  0.6\n",
      " |      2  1.000000  1.0\n",
      " |      \n",
      " |      In the above, the groups are not part of the index. We can have them included\n",
      " |      by using ``g2`` where ``group_keys=True``:\n",
      " |      \n",
      " |      >>> g2[['B', 'C']].apply(lambda x: x / x.sum())\n",
      " |                  B    C\n",
      " |      A\n",
      " |      a 0  0.333333  0.4\n",
      " |        1  0.666667  0.6\n",
      " |      b 2  1.000000  1.0\n",
      " |      \n",
      " |      Example 2: The function passed to `apply` takes a DataFrame as\n",
      " |      its argument and returns a Series.  `apply` combines the result for\n",
      " |      each group together into a new DataFrame.\n",
      " |      \n",
      " |      .. versionchanged:: 1.3.0\n",
      " |      \n",
      " |          The resulting dtype will reflect the return value of the passed ``func``.\n",
      " |      \n",
      " |      >>> g1[['B', 'C']].apply(lambda x: x.astype(float).max() - x.min())\n",
      " |           B    C\n",
      " |      A\n",
      " |      a  1.0  2.0\n",
      " |      b  0.0  0.0\n",
      " |      \n",
      " |      >>> g2[['B', 'C']].apply(lambda x: x.astype(float).max() - x.min())\n",
      " |           B    C\n",
      " |      A\n",
      " |      a  1.0  2.0\n",
      " |      b  0.0  0.0\n",
      " |      \n",
      " |      The ``group_keys`` argument has no effect here because the result is not\n",
      " |      like-indexed (i.e. :ref:`a transform <groupby.transform>`) when compared\n",
      " |      to the input.\n",
      " |      \n",
      " |      Example 3: The function passed to `apply` takes a DataFrame as\n",
      " |      its argument and returns a scalar. `apply` combines the result for\n",
      " |      each group together into a Series, including setting the index as\n",
      " |      appropriate:\n",
      " |      \n",
      " |      >>> g1.apply(lambda x: x.C.max() - x.B.min())\n",
      " |      A\n",
      " |      a    5\n",
      " |      b    2\n",
      " |      dtype: int64\n",
      " |  \n",
      " |  bfill(self, limit: 'int | None' = None)\n",
      " |      Backward fill the values.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      limit : int, optional\n",
      " |          Limit of how many values to fill.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Object with missing values filled.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.bfill :  Backward fill the missing values in the dataset.\n",
      " |      DataFrame.bfill:  Backward fill the missing values in the dataset.\n",
      " |      Series.fillna: Fill NaN values of a Series.\n",
      " |      DataFrame.fillna: Fill NaN values of a DataFrame.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      With Series:\n",
      " |      \n",
      " |      >>> index = ['Falcon', 'Falcon', 'Parrot', 'Parrot', 'Parrot']\n",
      " |      >>> s = pd.Series([None, 1, None, None, 3], index=index)\n",
      " |      >>> s\n",
      " |      Falcon    NaN\n",
      " |      Falcon    1.0\n",
      " |      Parrot    NaN\n",
      " |      Parrot    NaN\n",
      " |      Parrot    3.0\n",
      " |      dtype: float64\n",
      " |      >>> s.groupby(level=0).bfill()\n",
      " |      Falcon    1.0\n",
      " |      Falcon    1.0\n",
      " |      Parrot    3.0\n",
      " |      Parrot    3.0\n",
      " |      Parrot    3.0\n",
      " |      dtype: float64\n",
      " |      >>> s.groupby(level=0).bfill(limit=1)\n",
      " |      Falcon    1.0\n",
      " |      Falcon    1.0\n",
      " |      Parrot    NaN\n",
      " |      Parrot    3.0\n",
      " |      Parrot    3.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      With DataFrame:\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A': [1, None, None, None, 4],\n",
      " |      ...                    'B': [None, None, 5, None, 7]}, index=index)\n",
      " |      >>> df\n",
      " |                A         B\n",
      " |      Falcon  1.0       NaN\n",
      " |      Falcon  NaN       NaN\n",
      " |      Parrot  NaN       5.0\n",
      " |      Parrot  NaN       NaN\n",
      " |      Parrot  4.0       7.0\n",
      " |      >>> df.groupby(level=0).bfill()\n",
      " |                A         B\n",
      " |      Falcon  1.0       NaN\n",
      " |      Falcon  NaN       NaN\n",
      " |      Parrot  4.0       5.0\n",
      " |      Parrot  4.0       7.0\n",
      " |      Parrot  4.0       7.0\n",
      " |      >>> df.groupby(level=0).bfill(limit=1)\n",
      " |                A         B\n",
      " |      Falcon  1.0       NaN\n",
      " |      Falcon  NaN       NaN\n",
      " |      Parrot  NaN       5.0\n",
      " |      Parrot  4.0       7.0\n",
      " |      Parrot  4.0       7.0\n",
      " |  \n",
      " |  count(self) -> 'NDFrameT'\n",
      " |      Compute count of group, excluding missing values.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Count of values within each group.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.groupby : Apply a function groupby to a Series.\n",
      " |      DataFrame.groupby : Apply a function groupby\n",
      " |          to each row or column of a DataFrame.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      For SeriesGroupBy:\n",
      " |      \n",
      " |      >>> lst = ['a', 'a', 'b']\n",
      " |      >>> ser = pd.Series([1, 2, np.nan], index=lst)\n",
      " |      >>> ser\n",
      " |      a    1.0\n",
      " |      a    2.0\n",
      " |      b    NaN\n",
      " |      dtype: float64\n",
      " |      >>> ser.groupby(level=0).count()\n",
      " |      a    2\n",
      " |      b    0\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      For DataFrameGroupBy:\n",
      " |      \n",
      " |      >>> data = [[1, np.nan, 3], [1, np.nan, 6], [7, 8, 9]]\n",
      " |      >>> df = pd.DataFrame(data, columns=[\"a\", \"b\", \"c\"],\n",
      " |      ...                   index=[\"cow\", \"horse\", \"bull\"])\n",
      " |      >>> df\n",
      " |              a         b     c\n",
      " |      cow     1       NaN     3\n",
      " |      horse   1       NaN     6\n",
      " |      bull    7       8.0     9\n",
      " |      >>> df.groupby(\"a\").count()\n",
      " |          b   c\n",
      " |      a\n",
      " |      1   0   2\n",
      " |      7   1   1\n",
      " |      \n",
      " |      For Resampler:\n",
      " |      \n",
      " |      >>> ser = pd.Series([1, 2, 3, 4], index=pd.DatetimeIndex(\n",
      " |      ...                 ['2023-01-01', '2023-01-15', '2023-02-01', '2023-02-15']))\n",
      " |      >>> ser\n",
      " |      2023-01-01    1\n",
      " |      2023-01-15    2\n",
      " |      2023-02-01    3\n",
      " |      2023-02-15    4\n",
      " |      dtype: int64\n",
      " |      >>> ser.resample('MS').count()\n",
      " |      2023-01-01    2\n",
      " |      2023-02-01    2\n",
      " |      Freq: MS, dtype: int64\n",
      " |  \n",
      " |  cumcount(self, ascending: 'bool' = True)\n",
      " |      Number each item in each group from 0 to the length of that group - 1.\n",
      " |      \n",
      " |      Essentially this is equivalent to\n",
      " |      \n",
      " |      .. code-block:: python\n",
      " |      \n",
      " |          self.apply(lambda x: pd.Series(np.arange(len(x)), x.index))\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      ascending : bool, default True\n",
      " |          If False, number in reverse, from length of group - 1 to 0.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Sequence number of each element within each group.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      .ngroup : Number the groups themselves.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([['a'], ['a'], ['a'], ['b'], ['b'], ['a']],\n",
      " |      ...                   columns=['A'])\n",
      " |      >>> df\n",
      " |         A\n",
      " |      0  a\n",
      " |      1  a\n",
      " |      2  a\n",
      " |      3  b\n",
      " |      4  b\n",
      " |      5  a\n",
      " |      >>> df.groupby('A').cumcount()\n",
      " |      0    0\n",
      " |      1    1\n",
      " |      2    2\n",
      " |      3    0\n",
      " |      4    1\n",
      " |      5    3\n",
      " |      dtype: int64\n",
      " |      >>> df.groupby('A').cumcount(ascending=False)\n",
      " |      0    3\n",
      " |      1    2\n",
      " |      2    1\n",
      " |      3    1\n",
      " |      4    0\n",
      " |      5    0\n",
      " |      dtype: int64\n",
      " |  \n",
      " |  cummax(self, axis: 'AxisInt | lib.NoDefault' = <no_default>, numeric_only: 'bool' = False, **kwargs) -> 'NDFrameT'\n",
      " |      Cumulative max for each group.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.groupby : Apply a function groupby to a Series.\n",
      " |      DataFrame.groupby : Apply a function groupby\n",
      " |          to each row or column of a DataFrame.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      For SeriesGroupBy:\n",
      " |      \n",
      " |      >>> lst = ['a', 'a', 'a', 'b', 'b', 'b']\n",
      " |      >>> ser = pd.Series([1, 6, 2, 3, 1, 4], index=lst)\n",
      " |      >>> ser\n",
      " |      a    1\n",
      " |      a    6\n",
      " |      a    2\n",
      " |      b    3\n",
      " |      b    1\n",
      " |      b    4\n",
      " |      dtype: int64\n",
      " |      >>> ser.groupby(level=0).cummax()\n",
      " |      a    1\n",
      " |      a    6\n",
      " |      a    6\n",
      " |      b    3\n",
      " |      b    3\n",
      " |      b    4\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      For DataFrameGroupBy:\n",
      " |      \n",
      " |      >>> data = [[1, 8, 2], [1, 1, 0], [2, 6, 9]]\n",
      " |      >>> df = pd.DataFrame(data, columns=[\"a\", \"b\", \"c\"],\n",
      " |      ...                   index=[\"cow\", \"horse\", \"bull\"])\n",
      " |      >>> df\n",
      " |              a   b   c\n",
      " |      cow     1   8   2\n",
      " |      horse   1   1   0\n",
      " |      bull    2   6   9\n",
      " |      >>> df.groupby(\"a\").groups\n",
      " |      {1: ['cow', 'horse'], 2: ['bull']}\n",
      " |      >>> df.groupby(\"a\").cummax()\n",
      " |              b   c\n",
      " |      cow     8   2\n",
      " |      horse   8   2\n",
      " |      bull    6   9\n",
      " |  \n",
      " |  cummin(self, axis: 'AxisInt | lib.NoDefault' = <no_default>, numeric_only: 'bool' = False, **kwargs) -> 'NDFrameT'\n",
      " |      Cumulative min for each group.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.groupby : Apply a function groupby to a Series.\n",
      " |      DataFrame.groupby : Apply a function groupby\n",
      " |          to each row or column of a DataFrame.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      For SeriesGroupBy:\n",
      " |      \n",
      " |      >>> lst = ['a', 'a', 'a', 'b', 'b', 'b']\n",
      " |      >>> ser = pd.Series([1, 6, 2, 3, 0, 4], index=lst)\n",
      " |      >>> ser\n",
      " |      a    1\n",
      " |      a    6\n",
      " |      a    2\n",
      " |      b    3\n",
      " |      b    0\n",
      " |      b    4\n",
      " |      dtype: int64\n",
      " |      >>> ser.groupby(level=0).cummin()\n",
      " |      a    1\n",
      " |      a    1\n",
      " |      a    1\n",
      " |      b    3\n",
      " |      b    0\n",
      " |      b    0\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      For DataFrameGroupBy:\n",
      " |      \n",
      " |      >>> data = [[1, 0, 2], [1, 1, 5], [6, 6, 9]]\n",
      " |      >>> df = pd.DataFrame(data, columns=[\"a\", \"b\", \"c\"],\n",
      " |      ...                   index=[\"snake\", \"rabbit\", \"turtle\"])\n",
      " |      >>> df\n",
      " |              a   b   c\n",
      " |      snake   1   0   2\n",
      " |      rabbit  1   1   5\n",
      " |      turtle  6   6   9\n",
      " |      >>> df.groupby(\"a\").groups\n",
      " |      {1: ['snake', 'rabbit'], 6: ['turtle']}\n",
      " |      >>> df.groupby(\"a\").cummin()\n",
      " |              b   c\n",
      " |      snake   0   2\n",
      " |      rabbit  0   2\n",
      " |      turtle  6   9\n",
      " |  \n",
      " |  cumprod(self, axis: 'Axis | lib.NoDefault' = <no_default>, *args, **kwargs) -> 'NDFrameT'\n",
      " |      Cumulative product for each group.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.groupby : Apply a function groupby to a Series.\n",
      " |      DataFrame.groupby : Apply a function groupby\n",
      " |          to each row or column of a DataFrame.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      For SeriesGroupBy:\n",
      " |      \n",
      " |      >>> lst = ['a', 'a', 'b']\n",
      " |      >>> ser = pd.Series([6, 2, 0], index=lst)\n",
      " |      >>> ser\n",
      " |      a    6\n",
      " |      a    2\n",
      " |      b    0\n",
      " |      dtype: int64\n",
      " |      >>> ser.groupby(level=0).cumprod()\n",
      " |      a    6\n",
      " |      a   12\n",
      " |      b    0\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      For DataFrameGroupBy:\n",
      " |      \n",
      " |      >>> data = [[1, 8, 2], [1, 2, 5], [2, 6, 9]]\n",
      " |      >>> df = pd.DataFrame(data, columns=[\"a\", \"b\", \"c\"],\n",
      " |      ...                   index=[\"cow\", \"horse\", \"bull\"])\n",
      " |      >>> df\n",
      " |              a   b   c\n",
      " |      cow     1   8   2\n",
      " |      horse   1   2   5\n",
      " |      bull    2   6   9\n",
      " |      >>> df.groupby(\"a\").groups\n",
      " |      {1: ['cow', 'horse'], 2: ['bull']}\n",
      " |      >>> df.groupby(\"a\").cumprod()\n",
      " |              b   c\n",
      " |      cow     8   2\n",
      " |      horse  16  10\n",
      " |      bull    6   9\n",
      " |  \n",
      " |  cumsum(self, axis: 'Axis | lib.NoDefault' = <no_default>, *args, **kwargs) -> 'NDFrameT'\n",
      " |      Cumulative sum for each group.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.groupby : Apply a function groupby to a Series.\n",
      " |      DataFrame.groupby : Apply a function groupby\n",
      " |          to each row or column of a DataFrame.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      For SeriesGroupBy:\n",
      " |      \n",
      " |      >>> lst = ['a', 'a', 'b']\n",
      " |      >>> ser = pd.Series([6, 2, 0], index=lst)\n",
      " |      >>> ser\n",
      " |      a    6\n",
      " |      a    2\n",
      " |      b    0\n",
      " |      dtype: int64\n",
      " |      >>> ser.groupby(level=0).cumsum()\n",
      " |      a    6\n",
      " |      a    8\n",
      " |      b    0\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      For DataFrameGroupBy:\n",
      " |      \n",
      " |      >>> data = [[1, 8, 2], [1, 2, 5], [2, 6, 9]]\n",
      " |      >>> df = pd.DataFrame(data, columns=[\"a\", \"b\", \"c\"],\n",
      " |      ...                   index=[\"fox\", \"gorilla\", \"lion\"])\n",
      " |      >>> df\n",
      " |                a   b   c\n",
      " |      fox       1   8   2\n",
      " |      gorilla   1   2   5\n",
      " |      lion      2   6   9\n",
      " |      >>> df.groupby(\"a\").groups\n",
      " |      {1: ['fox', 'gorilla'], 2: ['lion']}\n",
      " |      >>> df.groupby(\"a\").cumsum()\n",
      " |                b   c\n",
      " |      fox       8   2\n",
      " |      gorilla  10   7\n",
      " |      lion      6   9\n",
      " |  \n",
      " |  describe(self, percentiles=None, include=None, exclude=None) -> 'NDFrameT'\n",
      " |      Generate descriptive statistics.\n",
      " |      \n",
      " |      Descriptive statistics include those that summarize the central\n",
      " |      tendency, dispersion and shape of a\n",
      " |      dataset's distribution, excluding ``NaN`` values.\n",
      " |      \n",
      " |      Analyzes both numeric and object series, as well\n",
      " |      as ``DataFrame`` column sets of mixed data types. The output\n",
      " |      will vary depending on what is provided. Refer to the notes\n",
      " |      below for more detail.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      percentiles : list-like of numbers, optional\n",
      " |          The percentiles to include in the output. All should\n",
      " |          fall between 0 and 1. The default is\n",
      " |          ``[.25, .5, .75]``, which returns the 25th, 50th, and\n",
      " |          75th percentiles.\n",
      " |      include : 'all', list-like of dtypes or None (default), optional\n",
      " |          A white list of data types to include in the result. Ignored\n",
      " |          for ``Series``. Here are the options:\n",
      " |      \n",
      " |          - 'all' : All columns of the input will be included in the output.\n",
      " |          - A list-like of dtypes : Limits the results to the\n",
      " |            provided data types.\n",
      " |            To limit the result to numeric types submit\n",
      " |            ``numpy.number``. To limit it instead to object columns submit\n",
      " |            the ``numpy.object`` data type. Strings\n",
      " |            can also be used in the style of\n",
      " |            ``select_dtypes`` (e.g. ``df.describe(include=['O'])``). To\n",
      " |            select pandas categorical columns, use ``'category'``\n",
      " |          - None (default) : The result will include all numeric columns.\n",
      " |      exclude : list-like of dtypes or None (default), optional,\n",
      " |          A black list of data types to omit from the result. Ignored\n",
      " |          for ``Series``. Here are the options:\n",
      " |      \n",
      " |          - A list-like of dtypes : Excludes the provided data types\n",
      " |            from the result. To exclude numeric types submit\n",
      " |            ``numpy.number``. To exclude object columns submit the data\n",
      " |            type ``numpy.object``. Strings can also be used in the style of\n",
      " |            ``select_dtypes`` (e.g. ``df.describe(exclude=['O'])``). To\n",
      " |            exclude pandas categorical columns, use ``'category'``\n",
      " |          - None (default) : The result will exclude nothing.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Summary statistics of the Series or Dataframe provided.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.count: Count number of non-NA/null observations.\n",
      " |      DataFrame.max: Maximum of the values in the object.\n",
      " |      DataFrame.min: Minimum of the values in the object.\n",
      " |      DataFrame.mean: Mean of the values.\n",
      " |      DataFrame.std: Standard deviation of the observations.\n",
      " |      DataFrame.select_dtypes: Subset of a DataFrame including/excluding\n",
      " |          columns based on their dtype.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      For numeric data, the result's index will include ``count``,\n",
      " |      ``mean``, ``std``, ``min``, ``max`` as well as lower, ``50`` and\n",
      " |      upper percentiles. By default the lower percentile is ``25`` and the\n",
      " |      upper percentile is ``75``. The ``50`` percentile is the\n",
      " |      same as the median.\n",
      " |      \n",
      " |      For object data (e.g. strings or timestamps), the result's index\n",
      " |      will include ``count``, ``unique``, ``top``, and ``freq``. The ``top``\n",
      " |      is the most common value. The ``freq`` is the most common value's\n",
      " |      frequency. Timestamps also include the ``first`` and ``last`` items.\n",
      " |      \n",
      " |      If multiple object values have the highest count, then the\n",
      " |      ``count`` and ``top`` results will be arbitrarily chosen from\n",
      " |      among those with the highest count.\n",
      " |      \n",
      " |      For mixed data types provided via a ``DataFrame``, the default is to\n",
      " |      return only an analysis of numeric columns. If the dataframe consists\n",
      " |      only of object and categorical data without any numeric columns, the\n",
      " |      default is to return an analysis of both the object and categorical\n",
      " |      columns. If ``include='all'`` is provided as an option, the result\n",
      " |      will include a union of attributes of each type.\n",
      " |      \n",
      " |      The `include` and `exclude` parameters can be used to limit\n",
      " |      which columns in a ``DataFrame`` are analyzed for the output.\n",
      " |      The parameters are ignored when analyzing a ``Series``.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Describing a numeric ``Series``.\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 2, 3])\n",
      " |      >>> s.describe()\n",
      " |      count    3.0\n",
      " |      mean     2.0\n",
      " |      std      1.0\n",
      " |      min      1.0\n",
      " |      25%      1.5\n",
      " |      50%      2.0\n",
      " |      75%      2.5\n",
      " |      max      3.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Describing a categorical ``Series``.\n",
      " |      \n",
      " |      >>> s = pd.Series(['a', 'a', 'b', 'c'])\n",
      " |      >>> s.describe()\n",
      " |      count     4\n",
      " |      unique    3\n",
      " |      top       a\n",
      " |      freq      2\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Describing a timestamp ``Series``.\n",
      " |      \n",
      " |      >>> s = pd.Series([\n",
      " |      ...     np.datetime64(\"2000-01-01\"),\n",
      " |      ...     np.datetime64(\"2010-01-01\"),\n",
      " |      ...     np.datetime64(\"2010-01-01\")\n",
      " |      ... ])\n",
      " |      >>> s.describe()\n",
      " |      count                      3\n",
      " |      mean     2006-09-01 08:00:00\n",
      " |      min      2000-01-01 00:00:00\n",
      " |      25%      2004-12-31 12:00:00\n",
      " |      50%      2010-01-01 00:00:00\n",
      " |      75%      2010-01-01 00:00:00\n",
      " |      max      2010-01-01 00:00:00\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Describing a ``DataFrame``. By default only numeric fields\n",
      " |      are returned.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'categorical': pd.Categorical(['d','e','f']),\n",
      " |      ...                    'numeric': [1, 2, 3],\n",
      " |      ...                    'object': ['a', 'b', 'c']\n",
      " |      ...                   })\n",
      " |      >>> df.describe()\n",
      " |             numeric\n",
      " |      count      3.0\n",
      " |      mean       2.0\n",
      " |      std        1.0\n",
      " |      min        1.0\n",
      " |      25%        1.5\n",
      " |      50%        2.0\n",
      " |      75%        2.5\n",
      " |      max        3.0\n",
      " |      \n",
      " |      Describing all columns of a ``DataFrame`` regardless of data type.\n",
      " |      \n",
      " |      >>> df.describe(include='all')  # doctest: +SKIP\n",
      " |             categorical  numeric object\n",
      " |      count            3      3.0      3\n",
      " |      unique           3      NaN      3\n",
      " |      top              f      NaN      a\n",
      " |      freq             1      NaN      1\n",
      " |      mean           NaN      2.0    NaN\n",
      " |      std            NaN      1.0    NaN\n",
      " |      min            NaN      1.0    NaN\n",
      " |      25%            NaN      1.5    NaN\n",
      " |      50%            NaN      2.0    NaN\n",
      " |      75%            NaN      2.5    NaN\n",
      " |      max            NaN      3.0    NaN\n",
      " |      \n",
      " |      Describing a column from a ``DataFrame`` by accessing it as\n",
      " |      an attribute.\n",
      " |      \n",
      " |      >>> df.numeric.describe()\n",
      " |      count    3.0\n",
      " |      mean     2.0\n",
      " |      std      1.0\n",
      " |      min      1.0\n",
      " |      25%      1.5\n",
      " |      50%      2.0\n",
      " |      75%      2.5\n",
      " |      max      3.0\n",
      " |      Name: numeric, dtype: float64\n",
      " |      \n",
      " |      Including only numeric columns in a ``DataFrame`` description.\n",
      " |      \n",
      " |      >>> df.describe(include=[np.number])\n",
      " |             numeric\n",
      " |      count      3.0\n",
      " |      mean       2.0\n",
      " |      std        1.0\n",
      " |      min        1.0\n",
      " |      25%        1.5\n",
      " |      50%        2.0\n",
      " |      75%        2.5\n",
      " |      max        3.0\n",
      " |      \n",
      " |      Including only string columns in a ``DataFrame`` description.\n",
      " |      \n",
      " |      >>> df.describe(include=[object])  # doctest: +SKIP\n",
      " |             object\n",
      " |      count       3\n",
      " |      unique      3\n",
      " |      top         a\n",
      " |      freq        1\n",
      " |      \n",
      " |      Including only categorical columns from a ``DataFrame`` description.\n",
      " |      \n",
      " |      >>> df.describe(include=['category'])\n",
      " |             categorical\n",
      " |      count            3\n",
      " |      unique           3\n",
      " |      top              d\n",
      " |      freq             1\n",
      " |      \n",
      " |      Excluding numeric columns from a ``DataFrame`` description.\n",
      " |      \n",
      " |      >>> df.describe(exclude=[np.number])  # doctest: +SKIP\n",
      " |             categorical object\n",
      " |      count            3      3\n",
      " |      unique           3      3\n",
      " |      top              f      a\n",
      " |      freq             1      1\n",
      " |      \n",
      " |      Excluding object columns from a ``DataFrame`` description.\n",
      " |      \n",
      " |      >>> df.describe(exclude=[object])  # doctest: +SKIP\n",
      " |             categorical  numeric\n",
      " |      count            3      3.0\n",
      " |      unique           3      NaN\n",
      " |      top              f      NaN\n",
      " |      freq             1      NaN\n",
      " |      mean           NaN      2.0\n",
      " |      std            NaN      1.0\n",
      " |      min            NaN      1.0\n",
      " |      25%            NaN      1.5\n",
      " |      50%            NaN      2.0\n",
      " |      75%            NaN      2.5\n",
      " |      max            NaN      3.0\n",
      " |  \n",
      " |  diff(self, periods: 'int' = 1, axis: 'AxisInt | lib.NoDefault' = <no_default>) -> 'NDFrameT'\n",
      " |      First discrete difference of element.\n",
      " |      \n",
      " |      Calculates the difference of each element compared with another\n",
      " |      element in the group (default is element in previous row).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      periods : int, default 1\n",
      " |          Periods to shift for calculating difference, accepts negative values.\n",
      " |      axis : axis to shift, default 0\n",
      " |          Take difference over rows (0) or columns (1).\n",
      " |      \n",
      " |          .. deprecated:: 2.1.0\n",
      " |              For axis=1, operate on the underlying object instead. Otherwise\n",
      " |              the axis keyword is not necessary.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          First differences.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.groupby : Apply a function groupby to a Series.\n",
      " |      DataFrame.groupby : Apply a function groupby\n",
      " |          to each row or column of a DataFrame.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      For SeriesGroupBy:\n",
      " |      \n",
      " |      >>> lst = ['a', 'a', 'a', 'b', 'b', 'b']\n",
      " |      >>> ser = pd.Series([7, 2, 8, 4, 3, 3], index=lst)\n",
      " |      >>> ser\n",
      " |      a     7\n",
      " |      a     2\n",
      " |      a     8\n",
      " |      b     4\n",
      " |      b     3\n",
      " |      b     3\n",
      " |      dtype: int64\n",
      " |      >>> ser.groupby(level=0).diff()\n",
      " |      a    NaN\n",
      " |      a   -5.0\n",
      " |      a    6.0\n",
      " |      b    NaN\n",
      " |      b   -1.0\n",
      " |      b    0.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      For DataFrameGroupBy:\n",
      " |      \n",
      " |      >>> data = {'a': [1, 3, 5, 7, 7, 8, 3], 'b': [1, 4, 8, 4, 4, 2, 1]}\n",
      " |      >>> df = pd.DataFrame(data, index=['dog', 'dog', 'dog',\n",
      " |      ...                   'mouse', 'mouse', 'mouse', 'mouse'])\n",
      " |      >>> df\n",
      " |               a  b\n",
      " |        dog    1  1\n",
      " |        dog    3  4\n",
      " |        dog    5  8\n",
      " |      mouse    7  4\n",
      " |      mouse    7  4\n",
      " |      mouse    8  2\n",
      " |      mouse    3  1\n",
      " |      >>> df.groupby(level=0).diff()\n",
      " |               a    b\n",
      " |        dog  NaN  NaN\n",
      " |        dog  2.0  3.0\n",
      " |        dog  2.0  4.0\n",
      " |      mouse  NaN  NaN\n",
      " |      mouse  0.0  0.0\n",
      " |      mouse  1.0 -2.0\n",
      " |      mouse -5.0 -1.0\n",
      " |  \n",
      " |  ewm(self, *args, **kwargs) -> 'ExponentialMovingWindowGroupby'\n",
      " |      Return an ewm grouper, providing ewm functionality per group.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      pandas.api.typing.ExponentialMovingWindowGroupby\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.groupby : Apply a function groupby to a Series.\n",
      " |      DataFrame.groupby : Apply a function groupby\n",
      " |          to each row or column of a DataFrame.\n",
      " |  \n",
      " |  expanding(self, *args, **kwargs) -> 'ExpandingGroupby'\n",
      " |      Return an expanding grouper, providing expanding\n",
      " |      functionality per group.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      pandas.api.typing.ExpandingGroupby\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.groupby : Apply a function groupby to a Series.\n",
      " |      DataFrame.groupby : Apply a function groupby\n",
      " |          to each row or column of a DataFrame.\n",
      " |  \n",
      " |  ffill(self, limit: 'int | None' = None)\n",
      " |      Forward fill the values.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      limit : int, optional\n",
      " |          Limit of how many values to fill.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Object with missing values filled.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.ffill: Returns Series with minimum number of char in object.\n",
      " |      DataFrame.ffill: Object with missing values filled or None if inplace=True.\n",
      " |      Series.fillna: Fill NaN values of a Series.\n",
      " |      DataFrame.fillna: Fill NaN values of a DataFrame.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      For SeriesGroupBy:\n",
      " |      \n",
      " |      >>> key = [0, 0, 1, 1]\n",
      " |      >>> ser = pd.Series([np.nan, 2, 3, np.nan], index=key)\n",
      " |      >>> ser\n",
      " |      0    NaN\n",
      " |      0    2.0\n",
      " |      1    3.0\n",
      " |      1    NaN\n",
      " |      dtype: float64\n",
      " |      >>> ser.groupby(level=0).ffill()\n",
      " |      0    NaN\n",
      " |      0    2.0\n",
      " |      1    3.0\n",
      " |      1    3.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      For DataFrameGroupBy:\n",
      " |      \n",
      " |      >>> df = pd.DataFrame(\n",
      " |      ...     {\n",
      " |      ...         \"key\": [0, 0, 1, 1, 1],\n",
      " |      ...         \"A\": [np.nan, 2, np.nan, 3, np.nan],\n",
      " |      ...         \"B\": [2, 3, np.nan, np.nan, np.nan],\n",
      " |      ...         \"C\": [np.nan, np.nan, 2, np.nan, np.nan],\n",
      " |      ...     }\n",
      " |      ... )\n",
      " |      >>> df\n",
      " |         key    A    B   C\n",
      " |      0    0  NaN  2.0 NaN\n",
      " |      1    0  2.0  3.0 NaN\n",
      " |      2    1  NaN  NaN 2.0\n",
      " |      3    1  3.0  NaN NaN\n",
      " |      4    1  NaN  NaN NaN\n",
      " |      \n",
      " |      Propagate non-null values forward or backward within each group along columns.\n",
      " |      \n",
      " |      >>> df.groupby(\"key\").ffill()\n",
      " |           A    B   C\n",
      " |      0  NaN  2.0 NaN\n",
      " |      1  2.0  3.0 NaN\n",
      " |      2  NaN  NaN 2.0\n",
      " |      3  3.0  NaN 2.0\n",
      " |      4  3.0  NaN 2.0\n",
      " |      \n",
      " |      Propagate non-null values forward or backward within each group along rows.\n",
      " |      \n",
      " |      >>> df.T.groupby(np.array([0, 0, 1, 1])).ffill().T\n",
      " |         key    A    B    C\n",
      " |      0  0.0  0.0  2.0  2.0\n",
      " |      1  0.0  2.0  3.0  3.0\n",
      " |      2  1.0  1.0  NaN  2.0\n",
      " |      3  1.0  3.0  NaN  NaN\n",
      " |      4  1.0  1.0  NaN  NaN\n",
      " |      \n",
      " |      Only replace the first NaN element within a group along rows.\n",
      " |      \n",
      " |      >>> df.groupby(\"key\").ffill(limit=1)\n",
      " |           A    B    C\n",
      " |      0  NaN  2.0  NaN\n",
      " |      1  2.0  3.0  NaN\n",
      " |      2  NaN  NaN  2.0\n",
      " |      3  3.0  NaN  2.0\n",
      " |      4  3.0  NaN  NaN\n",
      " |  \n",
      " |  first(self, numeric_only: 'bool' = False, min_count: 'int' = -1)\n",
      " |      Compute the first non-null entry of each column.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      numeric_only : bool, default False\n",
      " |          Include only float, int, boolean columns.\n",
      " |      min_count : int, default -1\n",
      " |          The required number of valid values to perform the operation. If fewer\n",
      " |          than ``min_count`` non-NA values are present the result will be NA.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          First non-null of values within each group.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.groupby : Apply a function groupby to each row or column of a\n",
      " |          DataFrame.\n",
      " |      pandas.core.groupby.DataFrameGroupBy.last : Compute the last non-null entry\n",
      " |          of each column.\n",
      " |      pandas.core.groupby.DataFrameGroupBy.nth : Take the nth row from each group.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame(dict(A=[1, 1, 3], B=[None, 5, 6], C=[1, 2, 3],\n",
      " |      ...                        D=['3/11/2000', '3/12/2000', '3/13/2000']))\n",
      " |      >>> df['D'] = pd.to_datetime(df['D'])\n",
      " |      >>> df.groupby(\"A\").first()\n",
      " |           B  C          D\n",
      " |      A\n",
      " |      1  5.0  1 2000-03-11\n",
      " |      3  6.0  3 2000-03-13\n",
      " |      >>> df.groupby(\"A\").first(min_count=2)\n",
      " |          B    C          D\n",
      " |      A\n",
      " |      1 NaN  1.0 2000-03-11\n",
      " |      3 NaN  NaN        NaT\n",
      " |      >>> df.groupby(\"A\").first(numeric_only=True)\n",
      " |           B  C\n",
      " |      A\n",
      " |      1  5.0  1\n",
      " |      3  6.0  3\n",
      " |  \n",
      " |  head(self, n: 'int' = 5) -> 'NDFrameT'\n",
      " |      Return first n rows of each group.\n",
      " |      \n",
      " |      Similar to ``.apply(lambda x: x.head(n))``, but it returns a subset of rows\n",
      " |      from the original DataFrame with original index and order preserved\n",
      " |      (``as_index`` flag is ignored).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : int\n",
      " |          If positive: number of entries to include from start of each group.\n",
      " |          If negative: number of entries to exclude from end of each group.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Subset of original Series or DataFrame as determined by n.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.groupby : Apply a function groupby to a Series.\n",
      " |      DataFrame.groupby : Apply a function groupby\n",
      " |          to each row or column of a DataFrame.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([[1, 2], [1, 4], [5, 6]],\n",
      " |      ...                   columns=['A', 'B'])\n",
      " |      >>> df.groupby('A').head(1)\n",
      " |         A  B\n",
      " |      0  1  2\n",
      " |      2  5  6\n",
      " |      >>> df.groupby('A').head(-1)\n",
      " |         A  B\n",
      " |      0  1  2\n",
      " |  \n",
      " |  last(self, numeric_only: 'bool' = False, min_count: 'int' = -1)\n",
      " |      Compute the last non-null entry of each column.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      numeric_only : bool, default False\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data.\n",
      " |      min_count : int, default -1\n",
      " |          The required number of valid values to perform the operation. If fewer\n",
      " |          than ``min_count`` non-NA values are present the result will be NA.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Last non-null of values within each group.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.groupby : Apply a function groupby to each row or column of a\n",
      " |          DataFrame.\n",
      " |      pandas.core.groupby.DataFrameGroupBy.first : Compute the first non-null entry\n",
      " |          of each column.\n",
      " |      pandas.core.groupby.DataFrameGroupBy.nth : Take the nth row from each group.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame(dict(A=[1, 1, 3], B=[5, None, 6], C=[1, 2, 3]))\n",
      " |      >>> df.groupby(\"A\").last()\n",
      " |           B  C\n",
      " |      A\n",
      " |      1  5.0  2\n",
      " |      3  6.0  3\n",
      " |  \n",
      " |  max(self, numeric_only: 'bool' = False, min_count: 'int' = -1, engine: \"Literal['cython', 'numba'] | None\" = None, engine_kwargs: 'dict[str, bool] | None' = None)\n",
      " |      Compute max of group values.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      numeric_only : bool, default False\n",
      " |          Include only float, int, boolean columns.\n",
      " |      \n",
      " |          .. versionchanged:: 2.0.0\n",
      " |      \n",
      " |              numeric_only no longer accepts ``None``.\n",
      " |      \n",
      " |      min_count : int, default -1\n",
      " |          The required number of valid values to perform the operation. If fewer\n",
      " |          than ``min_count`` non-NA values are present the result will be NA.\n",
      " |      \n",
      " |      engine : str, default None None\n",
      " |          * ``'cython'`` : Runs rolling apply through C-extensions from cython.\n",
      " |          * ``'numba'`` : Runs rolling apply through JIT compiled code from numba.\n",
      " |              Only available when ``raw`` is set to ``True``.\n",
      " |          * ``None`` : Defaults to ``'cython'`` or globally setting ``compute.use_numba``\n",
      " |      \n",
      " |      engine_kwargs : dict, default None None\n",
      " |          * For ``'cython'`` engine, there are no accepted ``engine_kwargs``\n",
      " |          * For ``'numba'`` engine, the engine can accept ``nopython``, ``nogil``\n",
      " |              and ``parallel`` dictionary keys. The values must either be ``True`` or\n",
      " |              ``False``. The default ``engine_kwargs`` for the ``'numba'`` engine is\n",
      " |              ``{'nopython': True, 'nogil': False, 'parallel': False}`` and will be\n",
      " |              applied to both the ``func`` and the ``apply`` groupby aggregation.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Computed max of values within each group.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      For SeriesGroupBy:\n",
      " |      \n",
      " |      >>> lst = ['a', 'a', 'b', 'b']\n",
      " |      >>> ser = pd.Series([1, 2, 3, 4], index=lst)\n",
      " |      >>> ser\n",
      " |      a    1\n",
      " |      a    2\n",
      " |      b    3\n",
      " |      b    4\n",
      " |      dtype: int64\n",
      " |      >>> ser.groupby(level=0).max()\n",
      " |      a    2\n",
      " |      b    4\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      For DataFrameGroupBy:\n",
      " |      \n",
      " |      >>> data = [[1, 8, 2], [1, 2, 5], [2, 5, 8], [2, 6, 9]]\n",
      " |      >>> df = pd.DataFrame(data, columns=[\"a\", \"b\", \"c\"],\n",
      " |      ...                   index=[\"tiger\", \"leopard\", \"cheetah\", \"lion\"])\n",
      " |      >>> df\n",
      " |                a  b  c\n",
      " |        tiger   1  8  2\n",
      " |      leopard   1  2  5\n",
      " |      cheetah   2  5  8\n",
      " |         lion   2  6  9\n",
      " |      >>> df.groupby(\"a\").max()\n",
      " |          b  c\n",
      " |      a\n",
      " |      1   8  5\n",
      " |      2   6  9\n",
      " |  \n",
      " |  mean(self, numeric_only: 'bool' = False, engine: \"Literal['cython', 'numba'] | None\" = None, engine_kwargs: 'dict[str, bool] | None' = None)\n",
      " |      Compute mean of groups, excluding missing values.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      numeric_only : bool, default False\n",
      " |          Include only float, int, boolean columns.\n",
      " |      \n",
      " |          .. versionchanged:: 2.0.0\n",
      " |      \n",
      " |              numeric_only no longer accepts ``None`` and defaults to ``False``.\n",
      " |      \n",
      " |      engine : str, default None\n",
      " |          * ``'cython'`` : Runs the operation through C-extensions from cython.\n",
      " |          * ``'numba'`` : Runs the operation through JIT compiled code from numba.\n",
      " |          * ``None`` : Defaults to ``'cython'`` or globally setting\n",
      " |            ``compute.use_numba``\n",
      " |      \n",
      " |          .. versionadded:: 1.4.0\n",
      " |      \n",
      " |      engine_kwargs : dict, default None\n",
      " |          * For ``'cython'`` engine, there are no accepted ``engine_kwargs``\n",
      " |          * For ``'numba'`` engine, the engine can accept ``nopython``, ``nogil``\n",
      " |            and ``parallel`` dictionary keys. The values must either be ``True`` or\n",
      " |            ``False``. The default ``engine_kwargs`` for the ``'numba'`` engine is\n",
      " |            ``{{'nopython': True, 'nogil': False, 'parallel': False}}``\n",
      " |      \n",
      " |          .. versionadded:: 1.4.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      pandas.Series or pandas.DataFrame\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.groupby : Apply a function groupby to a Series.\n",
      " |      DataFrame.groupby : Apply a function groupby\n",
      " |          to each row or column of a DataFrame.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A': [1, 1, 2, 1, 2],\n",
      " |      ...                    'B': [np.nan, 2, 3, 4, 5],\n",
      " |      ...                    'C': [1, 2, 1, 1, 2]}, columns=['A', 'B', 'C'])\n",
      " |      \n",
      " |      Groupby one column and return the mean of the remaining columns in\n",
      " |      each group.\n",
      " |      \n",
      " |      >>> df.groupby('A').mean()\n",
      " |           B         C\n",
      " |      A\n",
      " |      1  3.0  1.333333\n",
      " |      2  4.0  1.500000\n",
      " |      \n",
      " |      Groupby two columns and return the mean of the remaining column.\n",
      " |      \n",
      " |      >>> df.groupby(['A', 'B']).mean()\n",
      " |               C\n",
      " |      A B\n",
      " |      1 2.0  2.0\n",
      " |        4.0  1.0\n",
      " |      2 3.0  1.0\n",
      " |        5.0  2.0\n",
      " |      \n",
      " |      Groupby one column and return the mean of only particular column in\n",
      " |      the group.\n",
      " |      \n",
      " |      >>> df.groupby('A')['B'].mean()\n",
      " |      A\n",
      " |      1    3.0\n",
      " |      2    4.0\n",
      " |      Name: B, dtype: float64\n",
      " |  \n",
      " |  median(self, numeric_only: 'bool' = False)\n",
      " |      Compute median of groups, excluding missing values.\n",
      " |      \n",
      " |      For multiple groupings, the result index will be a MultiIndex\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      numeric_only : bool, default False\n",
      " |          Include only float, int, boolean columns.\n",
      " |      \n",
      " |          .. versionchanged:: 2.0.0\n",
      " |      \n",
      " |              numeric_only no longer accepts ``None`` and defaults to False.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Median of values within each group.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      For SeriesGroupBy:\n",
      " |      \n",
      " |      >>> lst = ['a', 'a', 'a', 'b', 'b', 'b']\n",
      " |      >>> ser = pd.Series([7, 2, 8, 4, 3, 3], index=lst)\n",
      " |      >>> ser\n",
      " |      a     7\n",
      " |      a     2\n",
      " |      a     8\n",
      " |      b     4\n",
      " |      b     3\n",
      " |      b     3\n",
      " |      dtype: int64\n",
      " |      >>> ser.groupby(level=0).median()\n",
      " |      a    7.0\n",
      " |      b    3.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      For DataFrameGroupBy:\n",
      " |      \n",
      " |      >>> data = {'a': [1, 3, 5, 7, 7, 8, 3], 'b': [1, 4, 8, 4, 4, 2, 1]}\n",
      " |      >>> df = pd.DataFrame(data, index=['dog', 'dog', 'dog',\n",
      " |      ...                   'mouse', 'mouse', 'mouse', 'mouse'])\n",
      " |      >>> df\n",
      " |               a  b\n",
      " |        dog    1  1\n",
      " |        dog    3  4\n",
      " |        dog    5  8\n",
      " |      mouse    7  4\n",
      " |      mouse    7  4\n",
      " |      mouse    8  2\n",
      " |      mouse    3  1\n",
      " |      >>> df.groupby(level=0).median()\n",
      " |               a    b\n",
      " |      dog    3.0  4.0\n",
      " |      mouse  7.0  3.0\n",
      " |      \n",
      " |      For Resampler:\n",
      " |      \n",
      " |      >>> ser = pd.Series([1, 2, 3, 3, 4, 5],\n",
      " |      ...                 index=pd.DatetimeIndex(['2023-01-01',\n",
      " |      ...                                         '2023-01-10',\n",
      " |      ...                                         '2023-01-15',\n",
      " |      ...                                         '2023-02-01',\n",
      " |      ...                                         '2023-02-10',\n",
      " |      ...                                         '2023-02-15']))\n",
      " |      >>> ser.resample('MS').median()\n",
      " |      2023-01-01    2.0\n",
      " |      2023-02-01    4.0\n",
      " |      Freq: MS, dtype: float64\n",
      " |  \n",
      " |  min(self, numeric_only: 'bool' = False, min_count: 'int' = -1, engine: \"Literal['cython', 'numba'] | None\" = None, engine_kwargs: 'dict[str, bool] | None' = None)\n",
      " |      Compute min of group values.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      numeric_only : bool, default False\n",
      " |          Include only float, int, boolean columns.\n",
      " |      \n",
      " |          .. versionchanged:: 2.0.0\n",
      " |      \n",
      " |              numeric_only no longer accepts ``None``.\n",
      " |      \n",
      " |      min_count : int, default -1\n",
      " |          The required number of valid values to perform the operation. If fewer\n",
      " |          than ``min_count`` non-NA values are present the result will be NA.\n",
      " |      \n",
      " |      engine : str, default None None\n",
      " |          * ``'cython'`` : Runs rolling apply through C-extensions from cython.\n",
      " |          * ``'numba'`` : Runs rolling apply through JIT compiled code from numba.\n",
      " |              Only available when ``raw`` is set to ``True``.\n",
      " |          * ``None`` : Defaults to ``'cython'`` or globally setting ``compute.use_numba``\n",
      " |      \n",
      " |      engine_kwargs : dict, default None None\n",
      " |          * For ``'cython'`` engine, there are no accepted ``engine_kwargs``\n",
      " |          * For ``'numba'`` engine, the engine can accept ``nopython``, ``nogil``\n",
      " |              and ``parallel`` dictionary keys. The values must either be ``True`` or\n",
      " |              ``False``. The default ``engine_kwargs`` for the ``'numba'`` engine is\n",
      " |              ``{'nopython': True, 'nogil': False, 'parallel': False}`` and will be\n",
      " |              applied to both the ``func`` and the ``apply`` groupby aggregation.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Computed min of values within each group.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      For SeriesGroupBy:\n",
      " |      \n",
      " |      >>> lst = ['a', 'a', 'b', 'b']\n",
      " |      >>> ser = pd.Series([1, 2, 3, 4], index=lst)\n",
      " |      >>> ser\n",
      " |      a    1\n",
      " |      a    2\n",
      " |      b    3\n",
      " |      b    4\n",
      " |      dtype: int64\n",
      " |      >>> ser.groupby(level=0).min()\n",
      " |      a    1\n",
      " |      b    3\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      For DataFrameGroupBy:\n",
      " |      \n",
      " |      >>> data = [[1, 8, 2], [1, 2, 5], [2, 5, 8], [2, 6, 9]]\n",
      " |      >>> df = pd.DataFrame(data, columns=[\"a\", \"b\", \"c\"],\n",
      " |      ...                   index=[\"tiger\", \"leopard\", \"cheetah\", \"lion\"])\n",
      " |      >>> df\n",
      " |                a  b  c\n",
      " |        tiger   1  8  2\n",
      " |      leopard   1  2  5\n",
      " |      cheetah   2  5  8\n",
      " |         lion   2  6  9\n",
      " |      >>> df.groupby(\"a\").min()\n",
      " |          b  c\n",
      " |      a\n",
      " |      1   2  2\n",
      " |      2   5  8\n",
      " |  \n",
      " |  ngroup(self, ascending: 'bool' = True)\n",
      " |      Number each group from 0 to the number of groups - 1.\n",
      " |      \n",
      " |      This is the enumerative complement of cumcount.  Note that the\n",
      " |      numbers given to the groups match the order in which the groups\n",
      " |      would be seen when iterating over the groupby object, not the\n",
      " |      order they are first observed.\n",
      " |      \n",
      " |      Groups with missing keys (where `pd.isna()` is True) will be labeled with `NaN`\n",
      " |      and will be skipped from the count.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      ascending : bool, default True\n",
      " |          If False, number in reverse, from number of group - 1 to 0.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Unique numbers for each group.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      .cumcount : Number the rows in each group.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({\"color\": [\"red\", None, \"red\", \"blue\", \"blue\", \"red\"]})\n",
      " |      >>> df\n",
      " |         color\n",
      " |      0    red\n",
      " |      1   None\n",
      " |      2    red\n",
      " |      3   blue\n",
      " |      4   blue\n",
      " |      5    red\n",
      " |      >>> df.groupby(\"color\").ngroup()\n",
      " |      0    1.0\n",
      " |      1    NaN\n",
      " |      2    1.0\n",
      " |      3    0.0\n",
      " |      4    0.0\n",
      " |      5    1.0\n",
      " |      dtype: float64\n",
      " |      >>> df.groupby(\"color\", dropna=False).ngroup()\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    1\n",
      " |      3    0\n",
      " |      4    0\n",
      " |      5    1\n",
      " |      dtype: int64\n",
      " |      >>> df.groupby(\"color\", dropna=False).ngroup(ascending=False)\n",
      " |      0    1\n",
      " |      1    0\n",
      " |      2    1\n",
      " |      3    2\n",
      " |      4    2\n",
      " |      5    1\n",
      " |      dtype: int64\n",
      " |  \n",
      " |  ohlc(self) -> 'DataFrame'\n",
      " |      Compute open, high, low and close values of a group, excluding missing values.\n",
      " |      \n",
      " |      For multiple groupings, the result index will be a MultiIndex\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Open, high, low and close values within each group.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      For SeriesGroupBy:\n",
      " |      \n",
      " |      >>> lst = ['SPX', 'CAC', 'SPX', 'CAC', 'SPX', 'CAC', 'SPX', 'CAC',]\n",
      " |      >>> ser = pd.Series([3.4, 9.0, 7.2, 5.2, 8.8, 9.4, 0.1, 0.5], index=lst)\n",
      " |      >>> ser\n",
      " |      SPX     3.4\n",
      " |      CAC     9.0\n",
      " |      SPX     7.2\n",
      " |      CAC     5.2\n",
      " |      SPX     8.8\n",
      " |      CAC     9.4\n",
      " |      SPX     0.1\n",
      " |      CAC     0.5\n",
      " |      dtype: float64\n",
      " |      >>> ser.groupby(level=0).ohlc()\n",
      " |           open  high  low  close\n",
      " |      CAC   9.0   9.4  0.5    0.5\n",
      " |      SPX   3.4   8.8  0.1    0.1\n",
      " |      \n",
      " |      For DataFrameGroupBy:\n",
      " |      \n",
      " |      >>> data = {2022: [1.2, 2.3, 8.9, 4.5, 4.4, 3, 2 , 1],\n",
      " |      ...         2023: [3.4, 9.0, 7.2, 5.2, 8.8, 9.4, 8.2, 1.0]}\n",
      " |      >>> df = pd.DataFrame(data, index=['SPX', 'CAC', 'SPX', 'CAC',\n",
      " |      ...                   'SPX', 'CAC', 'SPX', 'CAC'])\n",
      " |      >>> df\n",
      " |           2022  2023\n",
      " |      SPX   1.2   3.4\n",
      " |      CAC   2.3   9.0\n",
      " |      SPX   8.9   7.2\n",
      " |      CAC   4.5   5.2\n",
      " |      SPX   4.4   8.8\n",
      " |      CAC   3.0   9.4\n",
      " |      SPX   2.0   8.2\n",
      " |      CAC   1.0   1.0\n",
      " |      >>> df.groupby(level=0).ohlc()\n",
      " |          2022                 2023\n",
      " |          open high  low close open high  low close\n",
      " |      CAC  2.3  4.5  1.0   1.0  9.0  9.4  1.0   1.0\n",
      " |      SPX  1.2  8.9  1.2   2.0  3.4  8.8  3.4   8.2\n",
      " |      \n",
      " |      For Resampler:\n",
      " |      \n",
      " |      >>> ser = pd.Series([1, 3, 2, 4, 3, 5],\n",
      " |      ...                 index=pd.DatetimeIndex(['2023-01-01',\n",
      " |      ...                                         '2023-01-10',\n",
      " |      ...                                         '2023-01-15',\n",
      " |      ...                                         '2023-02-01',\n",
      " |      ...                                         '2023-02-10',\n",
      " |      ...                                         '2023-02-15']))\n",
      " |      >>> ser.resample('MS').ohlc()\n",
      " |                  open  high  low  close\n",
      " |      2023-01-01     1     3    1      2\n",
      " |      2023-02-01     4     5    3      5\n",
      " |  \n",
      " |  pct_change(self, periods: 'int' = 1, fill_method: 'FillnaOptions | None | lib.NoDefault' = <no_default>, limit: 'int | None | lib.NoDefault' = <no_default>, freq=None, axis: 'Axis | lib.NoDefault' = <no_default>)\n",
      " |      Calculate pct_change of each value to previous entry in group.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Percentage changes within each group.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.groupby : Apply a function groupby to a Series.\n",
      " |      DataFrame.groupby : Apply a function groupby\n",
      " |          to each row or column of a DataFrame.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      For SeriesGroupBy:\n",
      " |      \n",
      " |      >>> lst = ['a', 'a', 'b', 'b']\n",
      " |      >>> ser = pd.Series([1, 2, 3, 4], index=lst)\n",
      " |      >>> ser\n",
      " |      a    1\n",
      " |      a    2\n",
      " |      b    3\n",
      " |      b    4\n",
      " |      dtype: int64\n",
      " |      >>> ser.groupby(level=0).pct_change()\n",
      " |      a         NaN\n",
      " |      a    1.000000\n",
      " |      b         NaN\n",
      " |      b    0.333333\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      For DataFrameGroupBy:\n",
      " |      \n",
      " |      >>> data = [[1, 2, 3], [1, 5, 6], [2, 5, 8], [2, 6, 9]]\n",
      " |      >>> df = pd.DataFrame(data, columns=[\"a\", \"b\", \"c\"],\n",
      " |      ...                   index=[\"tuna\", \"salmon\", \"catfish\", \"goldfish\"])\n",
      " |      >>> df\n",
      " |                 a  b  c\n",
      " |          tuna   1  2  3\n",
      " |        salmon   1  5  6\n",
      " |       catfish   2  5  8\n",
      " |      goldfish   2  6  9\n",
      " |      >>> df.groupby(\"a\").pct_change()\n",
      " |                  b  c\n",
      " |          tuna    NaN    NaN\n",
      " |        salmon    1.5  1.000\n",
      " |       catfish    NaN    NaN\n",
      " |      goldfish    0.2  0.125\n",
      " |  \n",
      " |  prod(self, numeric_only: 'bool' = False, min_count: 'int' = 0)\n",
      " |      Compute prod of group values.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      numeric_only : bool, default False\n",
      " |          Include only float, int, boolean columns.\n",
      " |      \n",
      " |          .. versionchanged:: 2.0.0\n",
      " |      \n",
      " |              numeric_only no longer accepts ``None``.\n",
      " |      \n",
      " |      min_count : int, default 0\n",
      " |          The required number of valid values to perform the operation. If fewer\n",
      " |          than ``min_count`` non-NA values are present the result will be NA.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Computed prod of values within each group.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      For SeriesGroupBy:\n",
      " |      \n",
      " |      >>> lst = ['a', 'a', 'b', 'b']\n",
      " |      >>> ser = pd.Series([1, 2, 3, 4], index=lst)\n",
      " |      >>> ser\n",
      " |      a    1\n",
      " |      a    2\n",
      " |      b    3\n",
      " |      b    4\n",
      " |      dtype: int64\n",
      " |      >>> ser.groupby(level=0).prod()\n",
      " |      a    2\n",
      " |      b   12\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      For DataFrameGroupBy:\n",
      " |      \n",
      " |      >>> data = [[1, 8, 2], [1, 2, 5], [2, 5, 8], [2, 6, 9]]\n",
      " |      >>> df = pd.DataFrame(data, columns=[\"a\", \"b\", \"c\"],\n",
      " |      ...                   index=[\"tiger\", \"leopard\", \"cheetah\", \"lion\"])\n",
      " |      >>> df\n",
      " |                a  b  c\n",
      " |        tiger   1  8  2\n",
      " |      leopard   1  2  5\n",
      " |      cheetah   2  5  8\n",
      " |         lion   2  6  9\n",
      " |      >>> df.groupby(\"a\").prod()\n",
      " |           b    c\n",
      " |      a\n",
      " |      1   16   10\n",
      " |      2   30   72\n",
      " |  \n",
      " |  quantile(self, q: 'float | AnyArrayLike' = 0.5, interpolation: 'str' = 'linear', numeric_only: 'bool' = False)\n",
      " |      Return group values at the given quantile, a la numpy.percentile.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      q : float or array-like, default 0.5 (50% quantile)\n",
      " |          Value(s) between 0 and 1 providing the quantile(s) to compute.\n",
      " |      interpolation : {'linear', 'lower', 'higher', 'midpoint', 'nearest'}\n",
      " |          Method to use when the desired quantile falls between two points.\n",
      " |      numeric_only : bool, default False\n",
      " |          Include only `float`, `int` or `boolean` data.\n",
      " |      \n",
      " |          .. versionadded:: 1.5.0\n",
      " |      \n",
      " |          .. versionchanged:: 2.0.0\n",
      " |      \n",
      " |              numeric_only now defaults to ``False``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Return type determined by caller of GroupBy object.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.quantile : Similar method for Series.\n",
      " |      DataFrame.quantile : Similar method for DataFrame.\n",
      " |      numpy.percentile : NumPy method to compute qth percentile.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([\n",
      " |      ...     ['a', 1], ['a', 2], ['a', 3],\n",
      " |      ...     ['b', 1], ['b', 3], ['b', 5]\n",
      " |      ... ], columns=['key', 'val'])\n",
      " |      >>> df.groupby('key').quantile()\n",
      " |          val\n",
      " |      key\n",
      " |      a    2.0\n",
      " |      b    3.0\n",
      " |  \n",
      " |  rank(self, method: 'str' = 'average', ascending: 'bool' = True, na_option: 'str' = 'keep', pct: 'bool' = False, axis: 'AxisInt | lib.NoDefault' = <no_default>) -> 'NDFrameT'\n",
      " |      Provide the rank of values within each group.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      method : {'average', 'min', 'max', 'first', 'dense'}, default 'average'\n",
      " |          * average: average rank of group.\n",
      " |          * min: lowest rank in group.\n",
      " |          * max: highest rank in group.\n",
      " |          * first: ranks assigned in order they appear in the array.\n",
      " |          * dense: like 'min', but rank always increases by 1 between groups.\n",
      " |      ascending : bool, default True\n",
      " |          False for ranks by high (1) to low (N).\n",
      " |      na_option : {'keep', 'top', 'bottom'}, default 'keep'\n",
      " |          * keep: leave NA values where they are.\n",
      " |          * top: smallest rank if ascending.\n",
      " |          * bottom: smallest rank if descending.\n",
      " |      pct : bool, default False\n",
      " |          Compute percentage rank of data within each group.\n",
      " |      axis : int, default 0\n",
      " |          The axis of the object over which to compute the rank.\n",
      " |      \n",
      " |          .. deprecated:: 2.1.0\n",
      " |              For axis=1, operate on the underlying object instead. Otherwise\n",
      " |              the axis keyword is not necessary.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame with ranking of values within each group\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.groupby : Apply a function groupby to a Series.\n",
      " |      DataFrame.groupby : Apply a function groupby\n",
      " |          to each row or column of a DataFrame.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame(\n",
      " |      ...     {\n",
      " |      ...         \"group\": [\"a\", \"a\", \"a\", \"a\", \"a\", \"b\", \"b\", \"b\", \"b\", \"b\"],\n",
      " |      ...         \"value\": [2, 4, 2, 3, 5, 1, 2, 4, 1, 5],\n",
      " |      ...     }\n",
      " |      ... )\n",
      " |      >>> df\n",
      " |        group  value\n",
      " |      0     a      2\n",
      " |      1     a      4\n",
      " |      2     a      2\n",
      " |      3     a      3\n",
      " |      4     a      5\n",
      " |      5     b      1\n",
      " |      6     b      2\n",
      " |      7     b      4\n",
      " |      8     b      1\n",
      " |      9     b      5\n",
      " |      >>> for method in ['average', 'min', 'max', 'dense', 'first']:\n",
      " |      ...     df[f'{method}_rank'] = df.groupby('group')['value'].rank(method)\n",
      " |      >>> df\n",
      " |        group  value  average_rank  min_rank  max_rank  dense_rank  first_rank\n",
      " |      0     a      2           1.5       1.0       2.0         1.0         1.0\n",
      " |      1     a      4           4.0       4.0       4.0         3.0         4.0\n",
      " |      2     a      2           1.5       1.0       2.0         1.0         2.0\n",
      " |      3     a      3           3.0       3.0       3.0         2.0         3.0\n",
      " |      4     a      5           5.0       5.0       5.0         4.0         5.0\n",
      " |      5     b      1           1.5       1.0       2.0         1.0         1.0\n",
      " |      6     b      2           3.0       3.0       3.0         2.0         3.0\n",
      " |      7     b      4           4.0       4.0       4.0         3.0         4.0\n",
      " |      8     b      1           1.5       1.0       2.0         1.0         2.0\n",
      " |      9     b      5           5.0       5.0       5.0         4.0         5.0\n",
      " |  \n",
      " |  resample(self, rule, *args, **kwargs)\n",
      " |      Provide resampling when using a TimeGrouper.\n",
      " |      \n",
      " |      Given a grouper, the function resamples it according to a string\n",
      " |      \"string\" -> \"frequency\".\n",
      " |      \n",
      " |      See the :ref:`frequency aliases <timeseries.offset_aliases>`\n",
      " |      documentation for more details.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      rule : str or DateOffset\n",
      " |          The offset string or object representing target grouper conversion.\n",
      " |      *args, **kwargs\n",
      " |          Possible arguments are `how`, `fill_method`, `limit`, `kind` and\n",
      " |          `on`, and other arguments of `TimeGrouper`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      pandas.api.typing.DatetimeIndexResamplerGroupby,\n",
      " |      pandas.api.typing.PeriodIndexResamplerGroupby, or\n",
      " |      pandas.api.typing.TimedeltaIndexResamplerGroupby\n",
      " |          Return a new groupby object, with type depending on the data\n",
      " |          being resampled.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Grouper : Specify a frequency to resample with when\n",
      " |          grouping by a key.\n",
      " |      DatetimeIndex.resample : Frequency conversion and resampling of\n",
      " |          time series.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> idx = pd.date_range('1/1/2000', periods=4, freq='T')\n",
      " |      >>> df = pd.DataFrame(data=4 * [range(2)],\n",
      " |      ...                   index=idx,\n",
      " |      ...                   columns=['a', 'b'])\n",
      " |      >>> df.iloc[2, 0] = 5\n",
      " |      >>> df\n",
      " |                          a  b\n",
      " |      2000-01-01 00:00:00  0  1\n",
      " |      2000-01-01 00:01:00  0  1\n",
      " |      2000-01-01 00:02:00  5  1\n",
      " |      2000-01-01 00:03:00  0  1\n",
      " |      \n",
      " |      Downsample the DataFrame into 3 minute bins and sum the values of\n",
      " |      the timestamps falling into a bin.\n",
      " |      \n",
      " |      >>> df.groupby('a').resample('3T').sum()\n",
      " |                               a  b\n",
      " |      a\n",
      " |      0   2000-01-01 00:00:00  0  2\n",
      " |          2000-01-01 00:03:00  0  1\n",
      " |      5   2000-01-01 00:00:00  5  1\n",
      " |      \n",
      " |      Upsample the series into 30 second bins.\n",
      " |      \n",
      " |      >>> df.groupby('a').resample('30S').sum()\n",
      " |                          a  b\n",
      " |      a\n",
      " |      0   2000-01-01 00:00:00  0  1\n",
      " |          2000-01-01 00:00:30  0  0\n",
      " |          2000-01-01 00:01:00  0  1\n",
      " |          2000-01-01 00:01:30  0  0\n",
      " |          2000-01-01 00:02:00  0  0\n",
      " |          2000-01-01 00:02:30  0  0\n",
      " |          2000-01-01 00:03:00  0  1\n",
      " |      5   2000-01-01 00:02:00  5  1\n",
      " |      \n",
      " |      Resample by month. Values are assigned to the month of the period.\n",
      " |      \n",
      " |      >>> df.groupby('a').resample('M').sum()\n",
      " |                  a  b\n",
      " |      a\n",
      " |      0   2000-01-31  0  3\n",
      " |      5   2000-01-31  5  1\n",
      " |      \n",
      " |      Downsample the series into 3 minute bins as above, but close the right\n",
      " |      side of the bin interval.\n",
      " |      \n",
      " |      >>> df.groupby('a').resample('3T', closed='right').sum()\n",
      " |                               a  b\n",
      " |      a\n",
      " |      0   1999-12-31 23:57:00  0  1\n",
      " |          2000-01-01 00:00:00  0  2\n",
      " |      5   2000-01-01 00:00:00  5  1\n",
      " |      \n",
      " |      Downsample the series into 3 minute bins and close the right side of\n",
      " |      the bin interval, but label each bin using the right edge instead of\n",
      " |      the left.\n",
      " |      \n",
      " |      >>> df.groupby('a').resample('3T', closed='right', label='right').sum()\n",
      " |                               a  b\n",
      " |      a\n",
      " |      0   2000-01-01 00:00:00  0  1\n",
      " |          2000-01-01 00:03:00  0  2\n",
      " |      5   2000-01-01 00:03:00  5  1\n",
      " |  \n",
      " |  rolling(self, *args, **kwargs) -> 'RollingGroupby'\n",
      " |      Return a rolling grouper, providing rolling functionality per group.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      window : int, timedelta, str, offset, or BaseIndexer subclass\n",
      " |          Size of the moving window.\n",
      " |      \n",
      " |          If an integer, the fixed number of observations used for\n",
      " |          each window.\n",
      " |      \n",
      " |          If a timedelta, str, or offset, the time period of each window. Each\n",
      " |          window will be a variable sized based on the observations included in\n",
      " |          the time-period. This is only valid for datetimelike indexes.\n",
      " |          To learn more about the offsets & frequency strings, please see `this link\n",
      " |          <https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases>`__.\n",
      " |      \n",
      " |          If a BaseIndexer subclass, the window boundaries\n",
      " |          based on the defined ``get_window_bounds`` method. Additional rolling\n",
      " |          keyword arguments, namely ``min_periods``, ``center``, ``closed`` and\n",
      " |          ``step`` will be passed to ``get_window_bounds``.\n",
      " |      \n",
      " |      min_periods : int, default None\n",
      " |          Minimum number of observations in window required to have a value;\n",
      " |          otherwise, result is ``np.nan``.\n",
      " |      \n",
      " |          For a window that is specified by an offset,\n",
      " |          ``min_periods`` will default to 1.\n",
      " |      \n",
      " |          For a window that is specified by an integer, ``min_periods`` will default\n",
      " |          to the size of the window.\n",
      " |      \n",
      " |      center : bool, default False\n",
      " |          If False, set the window labels as the right edge of the window index.\n",
      " |      \n",
      " |          If True, set the window labels as the center of the window index.\n",
      " |      \n",
      " |      win_type : str, default None\n",
      " |          If ``None``, all points are evenly weighted.\n",
      " |      \n",
      " |          If a string, it must be a valid `scipy.signal window function\n",
      " |          <https://docs.scipy.org/doc/scipy/reference/signal.windows.html#module-scipy.signal.windows>`__.\n",
      " |      \n",
      " |          Certain Scipy window types require additional parameters to be passed\n",
      " |          in the aggregation function. The additional parameters must match\n",
      " |          the keywords specified in the Scipy window type method signature.\n",
      " |      \n",
      " |      on : str, optional\n",
      " |          For a DataFrame, a column label or Index level on which\n",
      " |          to calculate the rolling window, rather than the DataFrame's index.\n",
      " |      \n",
      " |          Provided integer column is ignored and excluded from result since\n",
      " |          an integer index is not used to calculate the rolling window.\n",
      " |      \n",
      " |      axis : int or str, default 0\n",
      " |          If ``0`` or ``'index'``, roll across the rows.\n",
      " |      \n",
      " |          If ``1`` or ``'columns'``, roll across the columns.\n",
      " |      \n",
      " |          For `Series` this parameter is unused and defaults to 0.\n",
      " |      \n",
      " |      closed : str, default None\n",
      " |          If ``'right'``, the first point in the window is excluded from calculations.\n",
      " |      \n",
      " |          If ``'left'``, the last point in the window is excluded from calculations.\n",
      " |      \n",
      " |          If ``'both'``, no points in the window are excluded from calculations.\n",
      " |      \n",
      " |          If ``'neither'``, the first and last points in the window are excluded\n",
      " |          from calculations.\n",
      " |      \n",
      " |          Default ``None`` (``'right'``).\n",
      " |      \n",
      " |      method : str {'single', 'table'}, default 'single'\n",
      " |          Execute the rolling operation per single column or row (``'single'``)\n",
      " |          or over the entire object (``'table'``).\n",
      " |      \n",
      " |          This argument is only implemented when specifying ``engine='numba'``\n",
      " |          in the method call.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      pandas.api.typing.RollingGroupby\n",
      " |          Return a new grouper with our rolling appended.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.rolling : Calling object with Series data.\n",
      " |      DataFrame.rolling : Calling object with DataFrames.\n",
      " |      Series.groupby : Apply a function groupby to a Series.\n",
      " |      DataFrame.groupby : Apply a function groupby.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A': [1, 1, 2, 2],\n",
      " |      ...                    'B': [1, 2, 3, 4],\n",
      " |      ...                    'C': [0.362, 0.227, 1.267, -0.562]})\n",
      " |      >>> df\n",
      " |            A  B      C\n",
      " |      0     1  1  0.362\n",
      " |      1     1  2  0.227\n",
      " |      2     2  3  1.267\n",
      " |      3     2  4 -0.562\n",
      " |      \n",
      " |      >>> df.groupby('A').rolling(2).sum()\n",
      " |          B      C\n",
      " |      A\n",
      " |      1 0  NaN    NaN\n",
      " |        1  3.0  0.589\n",
      " |      2 2  NaN    NaN\n",
      " |        3  7.0  0.705\n",
      " |      \n",
      " |      >>> df.groupby('A').rolling(2, min_periods=1).sum()\n",
      " |          B      C\n",
      " |      A\n",
      " |      1 0  1.0  0.362\n",
      " |        1  3.0  0.589\n",
      " |      2 2  3.0  1.267\n",
      " |        3  7.0  0.705\n",
      " |      \n",
      " |      >>> df.groupby('A').rolling(2, on='B').sum()\n",
      " |          B      C\n",
      " |      A\n",
      " |      1 0  1    NaN\n",
      " |        1  2  0.589\n",
      " |      2 2  3    NaN\n",
      " |        3  4  0.705\n",
      " |  \n",
      " |  sample(self, n: 'int | None' = None, frac: 'float | None' = None, replace: 'bool' = False, weights: 'Sequence | Series | None' = None, random_state: 'RandomState | None' = None)\n",
      " |      Return a random sample of items from each group.\n",
      " |      \n",
      " |      You can use `random_state` for reproducibility.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : int, optional\n",
      " |          Number of items to return for each group. Cannot be used with\n",
      " |          `frac` and must be no larger than the smallest group unless\n",
      " |          `replace` is True. Default is one if `frac` is None.\n",
      " |      frac : float, optional\n",
      " |          Fraction of items to return. Cannot be used with `n`.\n",
      " |      replace : bool, default False\n",
      " |          Allow or disallow sampling of the same row more than once.\n",
      " |      weights : list-like, optional\n",
      " |          Default None results in equal probability weighting.\n",
      " |          If passed a list-like then values must have the same length as\n",
      " |          the underlying DataFrame or Series object and will be used as\n",
      " |          sampling probabilities after normalization within each group.\n",
      " |          Values must be non-negative with at least one positive element\n",
      " |          within each group.\n",
      " |      random_state : int, array-like, BitGenerator, np.random.RandomState, np.random.Generator, optional\n",
      " |          If int, array-like, or BitGenerator, seed for random number generator.\n",
      " |          If np.random.RandomState or np.random.Generator, use as given.\n",
      " |      \n",
      " |          .. versionchanged:: 1.4.0\n",
      " |      \n",
      " |              np.random.Generator objects now accepted\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          A new object of same type as caller containing items randomly\n",
      " |          sampled within each group from the caller object.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.sample: Generate random samples from a DataFrame object.\n",
      " |      numpy.random.choice: Generate a random sample from a given 1-D numpy\n",
      " |          array.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame(\n",
      " |      ...     {\"a\": [\"red\"] * 2 + [\"blue\"] * 2 + [\"black\"] * 2, \"b\": range(6)}\n",
      " |      ... )\n",
      " |      >>> df\n",
      " |             a  b\n",
      " |      0    red  0\n",
      " |      1    red  1\n",
      " |      2   blue  2\n",
      " |      3   blue  3\n",
      " |      4  black  4\n",
      " |      5  black  5\n",
      " |      \n",
      " |      Select one row at random for each distinct value in column a. The\n",
      " |      `random_state` argument can be used to guarantee reproducibility:\n",
      " |      \n",
      " |      >>> df.groupby(\"a\").sample(n=1, random_state=1)\n",
      " |             a  b\n",
      " |      4  black  4\n",
      " |      2   blue  2\n",
      " |      1    red  1\n",
      " |      \n",
      " |      Set `frac` to sample fixed proportions rather than counts:\n",
      " |      \n",
      " |      >>> df.groupby(\"a\")[\"b\"].sample(frac=0.5, random_state=2)\n",
      " |      5    5\n",
      " |      2    2\n",
      " |      0    0\n",
      " |      Name: b, dtype: int64\n",
      " |      \n",
      " |      Control sample probabilities within groups by setting weights:\n",
      " |      \n",
      " |      >>> df.groupby(\"a\").sample(\n",
      " |      ...     n=1,\n",
      " |      ...     weights=[1, 1, 1, 0, 0, 1],\n",
      " |      ...     random_state=1,\n",
      " |      ... )\n",
      " |             a  b\n",
      " |      5  black  5\n",
      " |      2   blue  2\n",
      " |      0    red  0\n",
      " |  \n",
      " |  sem(self, ddof: 'int' = 1, numeric_only: 'bool' = False)\n",
      " |      Compute standard error of the mean of groups, excluding missing values.\n",
      " |      \n",
      " |      For multiple groupings, the result index will be a MultiIndex.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      ddof : int, default 1\n",
      " |          Degrees of freedom.\n",
      " |      \n",
      " |      numeric_only : bool, default False\n",
      " |          Include only `float`, `int` or `boolean` data.\n",
      " |      \n",
      " |          .. versionadded:: 1.5.0\n",
      " |      \n",
      " |          .. versionchanged:: 2.0.0\n",
      " |      \n",
      " |              numeric_only now defaults to ``False``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Standard error of the mean of values within each group.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      For SeriesGroupBy:\n",
      " |      \n",
      " |      >>> lst = ['a', 'a', 'b', 'b']\n",
      " |      >>> ser = pd.Series([5, 10, 8, 14], index=lst)\n",
      " |      >>> ser\n",
      " |      a     5\n",
      " |      a    10\n",
      " |      b     8\n",
      " |      b    14\n",
      " |      dtype: int64\n",
      " |      >>> ser.groupby(level=0).sem()\n",
      " |      a    2.5\n",
      " |      b    3.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      For DataFrameGroupBy:\n",
      " |      \n",
      " |      >>> data = [[1, 12, 11], [1, 15, 2], [2, 5, 8], [2, 6, 12]]\n",
      " |      >>> df = pd.DataFrame(data, columns=[\"a\", \"b\", \"c\"],\n",
      " |      ...                   index=[\"tuna\", \"salmon\", \"catfish\", \"goldfish\"])\n",
      " |      >>> df\n",
      " |                 a   b   c\n",
      " |          tuna   1  12  11\n",
      " |        salmon   1  15   2\n",
      " |       catfish   2   5   8\n",
      " |      goldfish   2   6  12\n",
      " |      >>> df.groupby(\"a\").sem()\n",
      " |            b  c\n",
      " |      a\n",
      " |      1    1.5  4.5\n",
      " |      2    0.5  2.0\n",
      " |      \n",
      " |      For Resampler:\n",
      " |      \n",
      " |      >>> ser = pd.Series([1, 3, 2, 4, 3, 8],\n",
      " |      ...                 index=pd.DatetimeIndex(['2023-01-01',\n",
      " |      ...                                         '2023-01-10',\n",
      " |      ...                                         '2023-01-15',\n",
      " |      ...                                         '2023-02-01',\n",
      " |      ...                                         '2023-02-10',\n",
      " |      ...                                         '2023-02-15']))\n",
      " |      >>> ser.resample('MS').sem()\n",
      " |      2023-01-01    0.577350\n",
      " |      2023-02-01    1.527525\n",
      " |      Freq: MS, dtype: float64\n",
      " |  \n",
      " |  shift(self, periods: 'int | Sequence[int]' = 1, freq=None, axis: 'Axis | lib.NoDefault' = <no_default>, fill_value=<no_default>, suffix: 'str | None' = None)\n",
      " |      Shift each group by periods observations.\n",
      " |      \n",
      " |      If freq is passed, the index will be increased using the periods and the freq.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      periods : int | Sequence[int], default 1\n",
      " |          Number of periods to shift. If a list of values, shift each group by\n",
      " |          each period.\n",
      " |      freq : str, optional\n",
      " |          Frequency string.\n",
      " |      axis : axis to shift, default 0\n",
      " |          Shift direction.\n",
      " |      \n",
      " |          .. deprecated:: 2.1.0\n",
      " |              For axis=1, operate on the underlying object instead. Otherwise\n",
      " |              the axis keyword is not necessary.\n",
      " |      \n",
      " |      fill_value : optional\n",
      " |          The scalar value to use for newly introduced missing values.\n",
      " |      \n",
      " |          .. versionchanged:: 2.1.0\n",
      " |              Will raise a ``ValueError`` if ``freq`` is provided too.\n",
      " |      \n",
      " |      suffix : str, optional\n",
      " |          A string to add to each shifted column if there are multiple periods.\n",
      " |          Ignored otherwise.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Object shifted within each group.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Index.shift : Shift values of Index.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      For SeriesGroupBy:\n",
      " |      \n",
      " |      >>> lst = ['a', 'a', 'b', 'b']\n",
      " |      >>> ser = pd.Series([1, 2, 3, 4], index=lst)\n",
      " |      >>> ser\n",
      " |      a    1\n",
      " |      a    2\n",
      " |      b    3\n",
      " |      b    4\n",
      " |      dtype: int64\n",
      " |      >>> ser.groupby(level=0).shift(1)\n",
      " |      a    NaN\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      b    3.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      For DataFrameGroupBy:\n",
      " |      \n",
      " |      >>> data = [[1, 2, 3], [1, 5, 6], [2, 5, 8], [2, 6, 9]]\n",
      " |      >>> df = pd.DataFrame(data, columns=[\"a\", \"b\", \"c\"],\n",
      " |      ...                   index=[\"tuna\", \"salmon\", \"catfish\", \"goldfish\"])\n",
      " |      >>> df\n",
      " |                 a  b  c\n",
      " |          tuna   1  2  3\n",
      " |        salmon   1  5  6\n",
      " |       catfish   2  5  8\n",
      " |      goldfish   2  6  9\n",
      " |      >>> df.groupby(\"a\").shift(1)\n",
      " |                    b    c\n",
      " |          tuna    NaN  NaN\n",
      " |        salmon    2.0  3.0\n",
      " |       catfish    NaN  NaN\n",
      " |      goldfish    5.0  8.0\n",
      " |  \n",
      " |  size(self) -> 'DataFrame | Series'\n",
      " |      Compute group sizes.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame or Series\n",
      " |          Number of rows in each group as a Series if as_index is True\n",
      " |          or a DataFrame if as_index is False.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.groupby : Apply a function groupby to a Series.\n",
      " |      DataFrame.groupby : Apply a function groupby\n",
      " |          to each row or column of a DataFrame.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      For SeriesGroupBy:\n",
      " |      \n",
      " |      >>> lst = ['a', 'a', 'b']\n",
      " |      >>> ser = pd.Series([1, 2, 3], index=lst)\n",
      " |      >>> ser\n",
      " |      a     1\n",
      " |      a     2\n",
      " |      b     3\n",
      " |      dtype: int64\n",
      " |      >>> ser.groupby(level=0).size()\n",
      " |      a    2\n",
      " |      b    1\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> data = [[1, 2, 3], [1, 5, 6], [7, 8, 9]]\n",
      " |      >>> df = pd.DataFrame(data, columns=[\"a\", \"b\", \"c\"],\n",
      " |      ...                   index=[\"owl\", \"toucan\", \"eagle\"])\n",
      " |      >>> df\n",
      " |              a  b  c\n",
      " |      owl     1  2  3\n",
      " |      toucan  1  5  6\n",
      " |      eagle   7  8  9\n",
      " |      >>> df.groupby(\"a\").size()\n",
      " |      a\n",
      " |      1    2\n",
      " |      7    1\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      For Resampler:\n",
      " |      \n",
      " |      >>> ser = pd.Series([1, 2, 3], index=pd.DatetimeIndex(\n",
      " |      ...                 ['2023-01-01', '2023-01-15', '2023-02-01']))\n",
      " |      >>> ser\n",
      " |      2023-01-01    1\n",
      " |      2023-01-15    2\n",
      " |      2023-02-01    3\n",
      " |      dtype: int64\n",
      " |      >>> ser.resample('MS').size()\n",
      " |      2023-01-01    2\n",
      " |      2023-02-01    1\n",
      " |      Freq: MS, dtype: int64\n",
      " |  \n",
      " |  std(self, ddof: 'int' = 1, engine: \"Literal['cython', 'numba'] | None\" = None, engine_kwargs: 'dict[str, bool] | None' = None, numeric_only: 'bool' = False)\n",
      " |      Compute standard deviation of groups, excluding missing values.\n",
      " |      \n",
      " |      For multiple groupings, the result index will be a MultiIndex.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      ddof : int, default 1\n",
      " |          Degrees of freedom.\n",
      " |      \n",
      " |      engine : str, default None\n",
      " |          * ``'cython'`` : Runs the operation through C-extensions from cython.\n",
      " |          * ``'numba'`` : Runs the operation through JIT compiled code from numba.\n",
      " |          * ``None`` : Defaults to ``'cython'`` or globally setting\n",
      " |            ``compute.use_numba``\n",
      " |      \n",
      " |          .. versionadded:: 1.4.0\n",
      " |      \n",
      " |      engine_kwargs : dict, default None\n",
      " |          * For ``'cython'`` engine, there are no accepted ``engine_kwargs``\n",
      " |          * For ``'numba'`` engine, the engine can accept ``nopython``, ``nogil``\n",
      " |            and ``parallel`` dictionary keys. The values must either be ``True`` or\n",
      " |            ``False``. The default ``engine_kwargs`` for the ``'numba'`` engine is\n",
      " |            ``{{'nopython': True, 'nogil': False, 'parallel': False}}``\n",
      " |      \n",
      " |          .. versionadded:: 1.4.0\n",
      " |      \n",
      " |      numeric_only : bool, default False\n",
      " |          Include only `float`, `int` or `boolean` data.\n",
      " |      \n",
      " |          .. versionadded:: 1.5.0\n",
      " |      \n",
      " |          .. versionchanged:: 2.0.0\n",
      " |      \n",
      " |              numeric_only now defaults to ``False``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Standard deviation of values within each group.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.groupby : Apply a function groupby to a Series.\n",
      " |      DataFrame.groupby : Apply a function groupby\n",
      " |          to each row or column of a DataFrame.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      For SeriesGroupBy:\n",
      " |      \n",
      " |      >>> lst = ['a', 'a', 'a', 'b', 'b', 'b']\n",
      " |      >>> ser = pd.Series([7, 2, 8, 4, 3, 3], index=lst)\n",
      " |      >>> ser\n",
      " |      a     7\n",
      " |      a     2\n",
      " |      a     8\n",
      " |      b     4\n",
      " |      b     3\n",
      " |      b     3\n",
      " |      dtype: int64\n",
      " |      >>> ser.groupby(level=0).std()\n",
      " |      a    3.21455\n",
      " |      b    0.57735\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      For DataFrameGroupBy:\n",
      " |      \n",
      " |      >>> data = {'a': [1, 3, 5, 7, 7, 8, 3], 'b': [1, 4, 8, 4, 4, 2, 1]}\n",
      " |      >>> df = pd.DataFrame(data, index=['dog', 'dog', 'dog',\n",
      " |      ...                   'mouse', 'mouse', 'mouse', 'mouse'])\n",
      " |      >>> df\n",
      " |               a  b\n",
      " |        dog    1  1\n",
      " |        dog    3  4\n",
      " |        dog    5  8\n",
      " |      mouse    7  4\n",
      " |      mouse    7  4\n",
      " |      mouse    8  2\n",
      " |      mouse    3  1\n",
      " |      >>> df.groupby(level=0).std()\n",
      " |                    a         b\n",
      " |      dog    2.000000  3.511885\n",
      " |      mouse  2.217356  1.500000\n",
      " |  \n",
      " |  sum(self, numeric_only: 'bool' = False, min_count: 'int' = 0, engine: \"Literal['cython', 'numba'] | None\" = None, engine_kwargs: 'dict[str, bool] | None' = None)\n",
      " |      Compute sum of group values.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      numeric_only : bool, default False\n",
      " |          Include only float, int, boolean columns.\n",
      " |      \n",
      " |          .. versionchanged:: 2.0.0\n",
      " |      \n",
      " |              numeric_only no longer accepts ``None``.\n",
      " |      \n",
      " |      min_count : int, default 0\n",
      " |          The required number of valid values to perform the operation. If fewer\n",
      " |          than ``min_count`` non-NA values are present the result will be NA.\n",
      " |      \n",
      " |      engine : str, default None None\n",
      " |          * ``'cython'`` : Runs rolling apply through C-extensions from cython.\n",
      " |          * ``'numba'`` : Runs rolling apply through JIT compiled code from numba.\n",
      " |              Only available when ``raw`` is set to ``True``.\n",
      " |          * ``None`` : Defaults to ``'cython'`` or globally setting ``compute.use_numba``\n",
      " |      \n",
      " |      engine_kwargs : dict, default None None\n",
      " |          * For ``'cython'`` engine, there are no accepted ``engine_kwargs``\n",
      " |          * For ``'numba'`` engine, the engine can accept ``nopython``, ``nogil``\n",
      " |              and ``parallel`` dictionary keys. The values must either be ``True`` or\n",
      " |              ``False``. The default ``engine_kwargs`` for the ``'numba'`` engine is\n",
      " |              ``{'nopython': True, 'nogil': False, 'parallel': False}`` and will be\n",
      " |              applied to both the ``func`` and the ``apply`` groupby aggregation.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Computed sum of values within each group.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      For SeriesGroupBy:\n",
      " |      \n",
      " |      >>> lst = ['a', 'a', 'b', 'b']\n",
      " |      >>> ser = pd.Series([1, 2, 3, 4], index=lst)\n",
      " |      >>> ser\n",
      " |      a    1\n",
      " |      a    2\n",
      " |      b    3\n",
      " |      b    4\n",
      " |      dtype: int64\n",
      " |      >>> ser.groupby(level=0).sum()\n",
      " |      a    3\n",
      " |      b    7\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      For DataFrameGroupBy:\n",
      " |      \n",
      " |      >>> data = [[1, 8, 2], [1, 2, 5], [2, 5, 8], [2, 6, 9]]\n",
      " |      >>> df = pd.DataFrame(data, columns=[\"a\", \"b\", \"c\"],\n",
      " |      ...                   index=[\"tiger\", \"leopard\", \"cheetah\", \"lion\"])\n",
      " |      >>> df\n",
      " |                a  b  c\n",
      " |        tiger   1  8  2\n",
      " |      leopard   1  2  5\n",
      " |      cheetah   2  5  8\n",
      " |         lion   2  6  9\n",
      " |      >>> df.groupby(\"a\").sum()\n",
      " |           b   c\n",
      " |      a\n",
      " |      1   10   7\n",
      " |      2   11  17\n",
      " |  \n",
      " |  tail(self, n: 'int' = 5) -> 'NDFrameT'\n",
      " |      Return last n rows of each group.\n",
      " |      \n",
      " |      Similar to ``.apply(lambda x: x.tail(n))``, but it returns a subset of rows\n",
      " |      from the original DataFrame with original index and order preserved\n",
      " |      (``as_index`` flag is ignored).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : int\n",
      " |          If positive: number of entries to include from end of each group.\n",
      " |          If negative: number of entries to exclude from start of each group.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Subset of original Series or DataFrame as determined by n.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.groupby : Apply a function groupby to a Series.\n",
      " |      DataFrame.groupby : Apply a function groupby\n",
      " |          to each row or column of a DataFrame.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([['a', 1], ['a', 2], ['b', 1], ['b', 2]],\n",
      " |      ...                   columns=['A', 'B'])\n",
      " |      >>> df.groupby('A').tail(1)\n",
      " |         A  B\n",
      " |      1  a  2\n",
      " |      3  b  2\n",
      " |      >>> df.groupby('A').tail(-1)\n",
      " |         A  B\n",
      " |      1  a  2\n",
      " |      3  b  2\n",
      " |  \n",
      " |  var(self, ddof: 'int' = 1, engine: \"Literal['cython', 'numba'] | None\" = None, engine_kwargs: 'dict[str, bool] | None' = None, numeric_only: 'bool' = False)\n",
      " |      Compute variance of groups, excluding missing values.\n",
      " |      \n",
      " |      For multiple groupings, the result index will be a MultiIndex.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      ddof : int, default 1\n",
      " |          Degrees of freedom.\n",
      " |      \n",
      " |      engine : str, default None\n",
      " |          * ``'cython'`` : Runs the operation through C-extensions from cython.\n",
      " |          * ``'numba'`` : Runs the operation through JIT compiled code from numba.\n",
      " |          * ``None`` : Defaults to ``'cython'`` or globally setting\n",
      " |            ``compute.use_numba``\n",
      " |      \n",
      " |          .. versionadded:: 1.4.0\n",
      " |      \n",
      " |      engine_kwargs : dict, default None\n",
      " |          * For ``'cython'`` engine, there are no accepted ``engine_kwargs``\n",
      " |          * For ``'numba'`` engine, the engine can accept ``nopython``, ``nogil``\n",
      " |            and ``parallel`` dictionary keys. The values must either be ``True`` or\n",
      " |            ``False``. The default ``engine_kwargs`` for the ``'numba'`` engine is\n",
      " |            ``{{'nopython': True, 'nogil': False, 'parallel': False}}``\n",
      " |      \n",
      " |          .. versionadded:: 1.4.0\n",
      " |      \n",
      " |      numeric_only : bool, default False\n",
      " |          Include only `float`, `int` or `boolean` data.\n",
      " |      \n",
      " |          .. versionadded:: 1.5.0\n",
      " |      \n",
      " |          .. versionchanged:: 2.0.0\n",
      " |      \n",
      " |              numeric_only now defaults to ``False``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Variance of values within each group.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.groupby : Apply a function groupby to a Series.\n",
      " |      DataFrame.groupby : Apply a function groupby\n",
      " |          to each row or column of a DataFrame.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      For SeriesGroupBy:\n",
      " |      \n",
      " |      >>> lst = ['a', 'a', 'a', 'b', 'b', 'b']\n",
      " |      >>> ser = pd.Series([7, 2, 8, 4, 3, 3], index=lst)\n",
      " |      >>> ser\n",
      " |      a     7\n",
      " |      a     2\n",
      " |      a     8\n",
      " |      b     4\n",
      " |      b     3\n",
      " |      b     3\n",
      " |      dtype: int64\n",
      " |      >>> ser.groupby(level=0).var()\n",
      " |      a    10.333333\n",
      " |      b     0.333333\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      For DataFrameGroupBy:\n",
      " |      \n",
      " |      >>> data = {'a': [1, 3, 5, 7, 7, 8, 3], 'b': [1, 4, 8, 4, 4, 2, 1]}\n",
      " |      >>> df = pd.DataFrame(data, index=['dog', 'dog', 'dog',\n",
      " |      ...                   'mouse', 'mouse', 'mouse', 'mouse'])\n",
      " |      >>> df\n",
      " |               a  b\n",
      " |        dog    1  1\n",
      " |        dog    3  4\n",
      " |        dog    5  8\n",
      " |      mouse    7  4\n",
      " |      mouse    7  4\n",
      " |      mouse    8  2\n",
      " |      mouse    3  1\n",
      " |      >>> df.groupby(level=0).var()\n",
      " |                    a          b\n",
      " |      dog    4.000000  12.333333\n",
      " |      mouse  4.916667   2.250000\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from pandas.core.groupby.groupby.GroupBy:\n",
      " |  \n",
      " |  nth\n",
      " |      Take the nth row from each group if n is an int, otherwise a subset of rows.\n",
      " |      \n",
      " |      Can be either a call or an index. dropna is not available with index notation.\n",
      " |      Index notation accepts a comma separated list of integers and slices.\n",
      " |      \n",
      " |      If dropna, will take the nth non-null row, dropna is either\n",
      " |      'all' or 'any'; this is equivalent to calling dropna(how=dropna)\n",
      " |      before the groupby.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : int, slice or list of ints and slices\n",
      " |          A single nth value for the row or a list of nth values or slices.\n",
      " |      \n",
      " |          .. versionchanged:: 1.4.0\n",
      " |              Added slice and lists containing slices.\n",
      " |              Added index notation.\n",
      " |      \n",
      " |      dropna : {'any', 'all', None}, default None\n",
      " |          Apply the specified dropna operation before counting which row is\n",
      " |          the nth row. Only supported if n is an int.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          N-th value within each group.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.groupby : Apply a function groupby to a Series.\n",
      " |      DataFrame.groupby : Apply a function groupby\n",
      " |          to each row or column of a DataFrame.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A': [1, 1, 2, 1, 2],\n",
      " |      ...                    'B': [np.nan, 2, 3, 4, 5]}, columns=['A', 'B'])\n",
      " |      >>> g = df.groupby('A')\n",
      " |      >>> g.nth(0)\n",
      " |         A   B\n",
      " |      0  1 NaN\n",
      " |      2  2 3.0\n",
      " |      >>> g.nth(1)\n",
      " |         A   B\n",
      " |      1  1 2.0\n",
      " |      4  2 5.0\n",
      " |      >>> g.nth(-1)\n",
      " |         A   B\n",
      " |      3  1 4.0\n",
      " |      4  2 5.0\n",
      " |      >>> g.nth([0, 1])\n",
      " |         A   B\n",
      " |      0  1 NaN\n",
      " |      1  1 2.0\n",
      " |      2  2 3.0\n",
      " |      4  2 5.0\n",
      " |      >>> g.nth(slice(None, -1))\n",
      " |         A   B\n",
      " |      0  1 NaN\n",
      " |      1  1 2.0\n",
      " |      2  2 3.0\n",
      " |      \n",
      " |      Index notation may also be used\n",
      " |      \n",
      " |      >>> g.nth[0, 1]\n",
      " |         A   B\n",
      " |      0  1 NaN\n",
      " |      1  1 2.0\n",
      " |      2  2 3.0\n",
      " |      4  2 5.0\n",
      " |      >>> g.nth[:-1]\n",
      " |         A   B\n",
      " |      0  1 NaN\n",
      " |      1  1 2.0\n",
      " |      2  2 3.0\n",
      " |      \n",
      " |      Specifying `dropna` allows ignoring ``NaN`` values\n",
      " |      \n",
      " |      >>> g.nth(0, dropna='any')\n",
      " |         A   B\n",
      " |      1  1 2.0\n",
      " |      2  2 3.0\n",
      " |      \n",
      " |      When the specified ``n`` is larger than any of the groups, an\n",
      " |      empty DataFrame is returned\n",
      " |      \n",
      " |      >>> g.nth(3, dropna='any')\n",
      " |      Empty DataFrame\n",
      " |      Columns: [A, B]\n",
      " |      Index: []\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.groupby.groupby.BaseGroupBy:\n",
      " |  \n",
      " |  __iter__(self) -> 'Iterator[tuple[Hashable, NDFrameT]]'\n",
      " |      Groupby iterator.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Generator yielding sequence of (name, subsetted object)\n",
      " |      for each group\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      For SeriesGroupBy:\n",
      " |      \n",
      " |      >>> lst = ['a', 'a', 'b']\n",
      " |      >>> ser = pd.Series([1, 2, 3], index=lst)\n",
      " |      >>> ser\n",
      " |      a    1\n",
      " |      a    2\n",
      " |      b    3\n",
      " |      dtype: int64\n",
      " |      >>> for x, y in ser.groupby(level=0):\n",
      " |      ...     print(f'{x}\\n{y}\\n')\n",
      " |      a\n",
      " |      a    1\n",
      " |      a    2\n",
      " |      dtype: int64\n",
      " |      b\n",
      " |      b    3\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      For DataFrameGroupBy:\n",
      " |      \n",
      " |      >>> data = [[1, 2, 3], [1, 5, 6], [7, 8, 9]]\n",
      " |      >>> df = pd.DataFrame(data, columns=[\"a\", \"b\", \"c\"])\n",
      " |      >>> df\n",
      " |         a  b  c\n",
      " |      0  1  2  3\n",
      " |      1  1  5  6\n",
      " |      2  7  8  9\n",
      " |      >>> for x, y in df.groupby(by=[\"a\"]):\n",
      " |      ...     print(f'{x}\\n{y}\\n')\n",
      " |      (1,)\n",
      " |         a  b  c\n",
      " |      0  1  2  3\n",
      " |      1  1  5  6\n",
      " |      (7,)\n",
      " |         a  b  c\n",
      " |      2  7  8  9\n",
      " |      \n",
      " |      For Resampler:\n",
      " |      \n",
      " |      >>> ser = pd.Series([1, 2, 3, 4], index=pd.DatetimeIndex(\n",
      " |      ...                 ['2023-01-01', '2023-01-15', '2023-02-01', '2023-02-15']))\n",
      " |      >>> ser\n",
      " |      2023-01-01    1\n",
      " |      2023-01-15    2\n",
      " |      2023-02-01    3\n",
      " |      2023-02-15    4\n",
      " |      dtype: int64\n",
      " |      >>> for x, y in ser.resample('MS'):\n",
      " |      ...     print(f'{x}\\n{y}\\n')\n",
      " |      2023-01-01 00:00:00\n",
      " |      2023-01-01    1\n",
      " |      2023-01-15    2\n",
      " |      dtype: int64\n",
      " |      2023-02-01 00:00:00\n",
      " |      2023-02-01    3\n",
      " |      2023-02-15    4\n",
      " |      dtype: int64\n",
      " |  \n",
      " |  __len__(self) -> 'int'\n",
      " |  \n",
      " |  __repr__(self) -> 'str'\n",
      " |      Return a string representation for a particular object.\n",
      " |  \n",
      " |  get_group(self, name, obj=None) -> 'DataFrame | Series'\n",
      " |      Construct DataFrame from group with provided name.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      name : object\n",
      " |          The name of the group to get as a DataFrame.\n",
      " |      obj : DataFrame, default None\n",
      " |          The DataFrame to take the DataFrame out of.  If\n",
      " |          it is None, the object groupby was called on will\n",
      " |          be used.\n",
      " |      \n",
      " |          .. deprecated:: 2.1.0\n",
      " |              The obj is deprecated and will be removed in a future version.\n",
      " |              Do ``df.iloc[gb.indices.get(name)]``\n",
      " |              instead of ``gb.get_group(name, obj=df)``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      same type as obj\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      For SeriesGroupBy:\n",
      " |      \n",
      " |      >>> lst = ['a', 'a', 'b']\n",
      " |      >>> ser = pd.Series([1, 2, 3], index=lst)\n",
      " |      >>> ser\n",
      " |      a    1\n",
      " |      a    2\n",
      " |      b    3\n",
      " |      dtype: int64\n",
      " |      >>> ser.groupby(level=0).get_group(\"a\")\n",
      " |      a    1\n",
      " |      a    2\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      For DataFrameGroupBy:\n",
      " |      \n",
      " |      >>> data = [[1, 2, 3], [1, 5, 6], [7, 8, 9]]\n",
      " |      >>> df = pd.DataFrame(data, columns=[\"a\", \"b\", \"c\"],\n",
      " |      ...                   index=[\"owl\", \"toucan\", \"eagle\"])\n",
      " |      >>> df\n",
      " |              a  b  c\n",
      " |      owl     1  2  3\n",
      " |      toucan  1  5  6\n",
      " |      eagle   7  8  9\n",
      " |      >>> df.groupby(by=[\"a\"]).get_group(1)\n",
      " |              a  b  c\n",
      " |      owl     1  2  3\n",
      " |      toucan  1  5  6\n",
      " |      \n",
      " |      For Resampler:\n",
      " |      \n",
      " |      >>> ser = pd.Series([1, 2, 3, 4], index=pd.DatetimeIndex(\n",
      " |      ...                 ['2023-01-01', '2023-01-15', '2023-02-01', '2023-02-15']))\n",
      " |      >>> ser\n",
      " |      2023-01-01    1\n",
      " |      2023-01-15    2\n",
      " |      2023-02-01    3\n",
      " |      2023-02-15    4\n",
      " |      dtype: int64\n",
      " |      >>> ser.resample('MS').get_group('2023-01-01')\n",
      " |      2023-01-01    1\n",
      " |      2023-01-15    2\n",
      " |      dtype: int64\n",
      " |  \n",
      " |  pipe(self, func: 'Callable[..., T] | tuple[Callable[..., T], str]', *args, **kwargs) -> 'T'\n",
      " |      Apply a ``func`` with arguments to this GroupBy object and return its result.\n",
      " |      \n",
      " |      Use `.pipe` when you want to improve readability by chaining together\n",
      " |      functions that expect Series, DataFrames, GroupBy or Resampler objects.\n",
      " |      Instead of writing\n",
      " |      \n",
      " |      >>> h(g(f(df.groupby('group')), arg1=a), arg2=b, arg3=c)  # doctest: +SKIP\n",
      " |      \n",
      " |      You can write\n",
      " |      \n",
      " |      >>> (df.groupby('group')\n",
      " |      ...    .pipe(f)\n",
      " |      ...    .pipe(g, arg1=a)\n",
      " |      ...    .pipe(h, arg2=b, arg3=c))  # doctest: +SKIP\n",
      " |      \n",
      " |      which is much more readable.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : callable or tuple of (callable, str)\n",
      " |          Function to apply to this GroupBy object or, alternatively,\n",
      " |          a `(callable, data_keyword)` tuple where `data_keyword` is a\n",
      " |          string indicating the keyword of `callable` that expects the\n",
      " |          GroupBy object.\n",
      " |      args : iterable, optional\n",
      " |             Positional arguments passed into `func`.\n",
      " |      kwargs : dict, optional\n",
      " |               A dictionary of keyword arguments passed into `func`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      the return type of `func`.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.pipe : Apply a function with arguments to a series.\n",
      " |      DataFrame.pipe: Apply a function with arguments to a dataframe.\n",
      " |      apply : Apply function to each group instead of to the\n",
      " |          full GroupBy object.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      See more `here\n",
      " |      <https://pandas.pydata.org/pandas-docs/stable/user_guide/groupby.html#piping-function-calls>`_\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A': 'a b a b'.split(), 'B': [1, 2, 3, 4]})\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      0  a  1\n",
      " |      1  b  2\n",
      " |      2  a  3\n",
      " |      3  b  4\n",
      " |      \n",
      " |      To get the difference between each groups maximum and minimum value in one\n",
      " |      pass, you can do\n",
      " |      \n",
      " |      >>> df.groupby('A').pipe(lambda x: x.max() - x.min())\n",
      " |         B\n",
      " |      A\n",
      " |      a  2\n",
      " |      b  2\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from pandas.core.groupby.groupby.BaseGroupBy:\n",
      " |  \n",
      " |  groups\n",
      " |      Dict {group name -> group labels}.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      For SeriesGroupBy:\n",
      " |      \n",
      " |      >>> lst = ['a', 'a', 'b']\n",
      " |      >>> ser = pd.Series([1, 2, 3], index=lst)\n",
      " |      >>> ser\n",
      " |      a    1\n",
      " |      a    2\n",
      " |      b    3\n",
      " |      dtype: int64\n",
      " |      >>> ser.groupby(level=0).groups\n",
      " |      {'a': ['a', 'a'], 'b': ['b']}\n",
      " |      \n",
      " |      For DataFrameGroupBy:\n",
      " |      \n",
      " |      >>> data = [[1, 2, 3], [1, 5, 6], [7, 8, 9]]\n",
      " |      >>> df = pd.DataFrame(data, columns=[\"a\", \"b\", \"c\"])\n",
      " |      >>> df\n",
      " |         a  b  c\n",
      " |      0  1  2  3\n",
      " |      1  1  5  6\n",
      " |      2  7  8  9\n",
      " |      >>> df.groupby(by=[\"a\"]).groups\n",
      " |      {1: [0, 1], 7: [2]}\n",
      " |      \n",
      " |      For Resampler:\n",
      " |      \n",
      " |      >>> ser = pd.Series([1, 2, 3, 4], index=pd.DatetimeIndex(\n",
      " |      ...                 ['2023-01-01', '2023-01-15', '2023-02-01', '2023-02-15']))\n",
      " |      >>> ser\n",
      " |      2023-01-01    1\n",
      " |      2023-01-15    2\n",
      " |      2023-02-01    3\n",
      " |      2023-02-15    4\n",
      " |      dtype: int64\n",
      " |      >>> ser.resample('MS').groups\n",
      " |      {Timestamp('2023-01-01 00:00:00'): 2, Timestamp('2023-02-01 00:00:00'): 4}\n",
      " |  \n",
      " |  indices\n",
      " |      Dict {group name -> group indices}.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      For SeriesGroupBy:\n",
      " |      \n",
      " |      >>> lst = ['a', 'a', 'b']\n",
      " |      >>> ser = pd.Series([1, 2, 3], index=lst)\n",
      " |      >>> ser\n",
      " |      a    1\n",
      " |      a    2\n",
      " |      b    3\n",
      " |      dtype: int64\n",
      " |      >>> ser.groupby(level=0).indices\n",
      " |      {'a': array([0, 1]), 'b': array([2])}\n",
      " |      \n",
      " |      For DataFrameGroupBy:\n",
      " |      \n",
      " |      >>> data = [[1, 2, 3], [1, 5, 6], [7, 8, 9]]\n",
      " |      >>> df = pd.DataFrame(data, columns=[\"a\", \"b\", \"c\"],\n",
      " |      ...                   index=[\"owl\", \"toucan\", \"eagle\"])\n",
      " |      >>> df\n",
      " |              a  b  c\n",
      " |      owl     1  2  3\n",
      " |      toucan  1  5  6\n",
      " |      eagle   7  8  9\n",
      " |      >>> df.groupby(by=[\"a\"]).indices\n",
      " |      {1: array([0, 1]), 7: array([2])}\n",
      " |      \n",
      " |      For Resampler:\n",
      " |      \n",
      " |      >>> ser = pd.Series([1, 2, 3, 4], index=pd.DatetimeIndex(\n",
      " |      ...                 ['2023-01-01', '2023-01-15', '2023-02-01', '2023-02-15']))\n",
      " |      >>> ser\n",
      " |      2023-01-01    1\n",
      " |      2023-01-15    2\n",
      " |      2023-02-01    3\n",
      " |      2023-02-15    4\n",
      " |      dtype: int64\n",
      " |      >>> ser.resample('MS').indices\n",
      " |      defaultdict(<class 'list'>, {Timestamp('2023-01-01 00:00:00'): [0, 1],\n",
      " |      Timestamp('2023-02-01 00:00:00'): [2, 3]})\n",
      " |  \n",
      " |  ngroups\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from pandas.core.groupby.groupby.BaseGroupBy:\n",
      " |  \n",
      " |  keys = None\n",
      " |  \n",
      " |  level = None\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.base.PandasObject:\n",
      " |  \n",
      " |  __sizeof__(self) -> 'int'\n",
      " |      Generates the total memory usage for an object that returns\n",
      " |      either a value or Series of values\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.accessor.DirNamesMixin:\n",
      " |  \n",
      " |  __dir__(self) -> 'list[str]'\n",
      " |      Provide method name lookup and completion.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Only provide 'public' methods.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from pandas.core.accessor.DirNamesMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from pandas.core.base.SelectionMixin:\n",
      " |  \n",
      " |  ndim\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from typing.Generic:\n",
      " |  \n",
      " |  __class_getitem__(params) from builtins.type\n",
      " |      Parameterizes a generic class.\n",
      " |      \n",
      " |      At least, parameterizing a generic class is the *main* thing this method\n",
      " |      does. For example, for some generic class `Foo`, this is called when we\n",
      " |      do `Foo[int]` - there, with `cls=Foo` and `params=int`.\n",
      " |      \n",
      " |      However, note that this method is also called when defining generic\n",
      " |      classes in the first place with `class Foo(Generic[T]): ...`.\n",
      " |  \n",
      " |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      " |      This method is called when a class is subclassed.\n",
      " |      \n",
      " |      The default implementation does nothing. It may be\n",
      " |      overridden to extend subclasses.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(titanic_subset.groupby('Sex'))."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb5c1d0",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "groupby object has many useful methods for processing data by group."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8648838a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Aggregation methods \n",
    "\n",
    "- Methods that compute statistics across the different groups.\n",
    "- Common aggregation methods:\n",
    "    - .min(): returns the minimum value for each column by group\n",
    "    - .max(): returns the maximum value for each column by group\n",
    "    - .mean(): returns the average value for each column by group\n",
    "    - .median(): returns the median value for each column by group\n",
    "    - .count(): returns the count of each column by group\n",
    "    - .sum(): return sum of each column by group"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624681ac",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Computing the mean of columns by group:\n",
    "- Note: mean of Survived is the survival fraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c943888",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>female</th>\n",
       "      <td>0.742038</td>\n",
       "      <td>27.915709</td>\n",
       "      <td>44.479818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td>0.188908</td>\n",
       "      <td>30.726645</td>\n",
       "      <td>25.523893</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Survived        Age       Fare\n",
       "Sex                                   \n",
       "female  0.742038  27.915709  44.479818\n",
       "male    0.188908  30.726645  25.523893"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_subset.groupby('Sex').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0bf6ecb",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Any obvious distinctions between groups here?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775e214d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### .agg(func) method\n",
    "Can write your own aggregations.\n",
    "- Get square root of the sum of squares of desired columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "912a1728",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>female</th>\n",
       "      <td>15.264338</td>\n",
       "      <td>505.132532</td>\n",
       "      <td>1293.863603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td>10.440307</td>\n",
       "      <td>724.618934</td>\n",
       "      <td>1203.237998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Survived         Age         Fare\n",
       "Sex                                       \n",
       "female  15.264338  505.132532  1293.863603\n",
       "male    10.440307  724.618934  1203.237998"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_subset.groupby('Sex').agg(lambda x: np.sqrt(np.sum(x**2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32b72e9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### .transform(func) method\n",
    "- This is not an aggregation.\n",
    "- Transforms entries in each column differently according to their group.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec1a61b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Example: standardize columns for each sex separately:\n",
    "\n",
    "- Subtract entries of columns in each sex category by the column mean for that sex.\n",
    "- Then divide by the standard deviation of fare for that sex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e3c2a6d",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "sexdifferentiated = titanic_subset.groupby('Sex').transform(lambda col: (col - col.mean())/col.std() )\n",
    "sexdifferentiated['Sex'] = titanic_subset['Sex']\n",
    "#titanic_subset.apply(lambda col: (col - col.mean())/col.std(ddof = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e981452b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.482185</td>\n",
       "      <td>-0.594531</td>\n",
       "      <td>-0.423612</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.588670</td>\n",
       "      <td>0.714684</td>\n",
       "      <td>0.462147</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.588670</td>\n",
       "      <td>-0.135768</td>\n",
       "      <td>-0.630280</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.588670</td>\n",
       "      <td>0.502071</td>\n",
       "      <td>0.148630</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.482185</td>\n",
       "      <td>0.291136</td>\n",
       "      <td>-0.405067</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>-0.482185</td>\n",
       "      <td>-0.253890</td>\n",
       "      <td>-0.290320</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>0.588670</td>\n",
       "      <td>-0.631865</td>\n",
       "      <td>-0.249662</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>-1.693335</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.362597</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>2.070299</td>\n",
       "      <td>-0.322018</td>\n",
       "      <td>0.103762</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>-0.482185</td>\n",
       "      <td>0.086751</td>\n",
       "      <td>-0.412022</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived       Age      Fare     Sex\n",
       "0   -0.482185 -0.594531 -0.423612    male\n",
       "1    0.588670  0.714684  0.462147  female\n",
       "2    0.588670 -0.135768 -0.630280  female\n",
       "3    0.588670  0.502071  0.148630  female\n",
       "4   -0.482185  0.291136 -0.405067    male\n",
       "..        ...       ...       ...     ...\n",
       "886 -0.482185 -0.253890 -0.290320    male\n",
       "887  0.588670 -0.631865 -0.249662  female\n",
       "888 -1.693335       NaN -0.362597  female\n",
       "889  2.070299 -0.322018  0.103762    male\n",
       "890 -0.482185  0.086751 -0.412022    male\n",
       "\n",
       "[891 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sexdifferentiated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0185da2a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Grouping by multiple categorical variables\n",
    "\n",
    "- Split data into multiple levels of groups. \n",
    "- Group by sex (Male/Female) with subgroups in each according to passenger class.\n",
    "\n",
    "df.groupby() takes in list of categorical columns to group on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd1eef20",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pandas.core.groupby.generic.DataFrameGroupBy object at 0x0000021BA5CC42D0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_subset2 = titanic_df[['Sex', 'Pclass', 'Survived', 'Age', 'Fare']]\n",
    "titanic_subset2.groupby(['Sex','Pclass'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56c79fc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Calculate mean of attributes within these groups/subgroups:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3534e9ad",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">Survived</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Age</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Fare</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <th>Pclass</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">female</th>\n",
       "      <th>1</th>\n",
       "      <td>0.968085</td>\n",
       "      <td>0.176716</td>\n",
       "      <td>34.611765</td>\n",
       "      <td>13.612052</td>\n",
       "      <td>106.125798</td>\n",
       "      <td>74.259988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.921053</td>\n",
       "      <td>0.271448</td>\n",
       "      <td>28.722973</td>\n",
       "      <td>12.872702</td>\n",
       "      <td>21.970121</td>\n",
       "      <td>10.891796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.501745</td>\n",
       "      <td>21.750000</td>\n",
       "      <td>12.729964</td>\n",
       "      <td>16.118810</td>\n",
       "      <td>11.690314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">male</th>\n",
       "      <th>1</th>\n",
       "      <td>0.368852</td>\n",
       "      <td>0.484484</td>\n",
       "      <td>41.281386</td>\n",
       "      <td>15.139570</td>\n",
       "      <td>67.226127</td>\n",
       "      <td>77.548021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.157407</td>\n",
       "      <td>0.365882</td>\n",
       "      <td>30.740707</td>\n",
       "      <td>14.793894</td>\n",
       "      <td>19.741782</td>\n",
       "      <td>14.922235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.135447</td>\n",
       "      <td>0.342694</td>\n",
       "      <td>26.507589</td>\n",
       "      <td>12.159514</td>\n",
       "      <td>12.661633</td>\n",
       "      <td>11.681696</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Survived                  Age                   Fare           \n",
       "                   mean       std       mean        std        mean        std\n",
       "Sex    Pclass                                                                 \n",
       "female 1       0.968085  0.176716  34.611765  13.612052  106.125798  74.259988\n",
       "       2       0.921053  0.271448  28.722973  12.872702   21.970121  10.891796\n",
       "       3       0.500000  0.501745  21.750000  12.729964   16.118810  11.690314\n",
       "male   1       0.368852  0.484484  41.281386  15.139570   67.226127  77.548021\n",
       "       2       0.157407  0.365882  30.740707  14.793894   19.741782  14.922235\n",
       "       3       0.135447  0.342694  26.507589  12.159514   12.661633  11.681696"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_df = titanic_subset2.groupby(['Sex','Pclass']).agg(['mean', 'std'])\n",
    "grouped_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6bdcbe",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The values are now set on a hierarchical multi-index.\n",
    "\n",
    "- Multi-indexing: extremely powerful.\n",
    "- Will cover the mechanics next lecture.\n",
    "\n",
    "Visualize survival rates and average fare paid by the subgroups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3665a94a",
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x700 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# a little column renaming\n",
    "grouped_df.rename(columns = {'Survived': 'Survival'}, \n",
    "                  index = {1: 'Class 1', 2: 'Class 2', 3: 'Class 3'}, inplace = True)\n",
    "grouped_df.index.set_names('Passenger class', level = 1, inplace = True)\n",
    "\n",
    "# quick and dirty plot for sex/class disparity information\n",
    "grouped_df[['Survival', 'Fare']].unstack().plot.bar(subplots=True, layout = (3,3), figsize = (7,7),\n",
    "                                                         legend = False, sharex = True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30fe792c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Essentially: \n",
    "- One groupby operation\n",
    "- One pandas plot call\n",
    "\n",
    "Result: informative visualization on sex/class disparity.\n",
    "\n",
    "Groupbys clearly allow us to start reforming data/asking interesting questions!"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
